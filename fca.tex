\documentclass[11pt]{article}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[normalem]{ulem}
\newcommand{\numpy}{{\tt numpy}}    % tt font for numpy

\topmargin -.5in
\textheight 9in
\oddsidemargin -.25in
\evensidemargin -.25in
\textwidth 7in

\begin{document}

% ========== Edit your name here
\author{Simone Montali - monta.li}
\title{Fondamenti di Controlli Automatici}

\maketitle

\medskip
\section{Il controllo attivo di un processo}
Innanzitutto definiamo due termini fondamentali per la materia: un \textbf{processo} è l'evoluzione nel tempo di ciò che caratterizza un sistema. Con \textbf{controllo attivo} intendiamo una strategia di controllo che prevede un'azione di comando esercitata sul processo. 
Il controllo attivo risolve il problema di imporre una modalità di funzionamento desiderato ad un processo: l'obiettivo è che una variabile del processo coincida con una preassegnata. Parliamo di \textbf{regolazione} quando l'ingresso è costante, di \textbf{asservimento} quando l'ingresso è variabile. 
Un \textbf{sistema} è un complesso, normalmente composto da più elementi interconnessi, in cui si possono distinguere grandezze soggette a variare nel tempo (variabili). Un \textbf{segnale} è una funzione che rappresenta l'andamento delle variabili nel tempo. Distinguiamo queste ultime in indipendenti (ingressi) e dipendenti (uscite). Arriviamo così al concetto di \textbf{sistema orientato}. Un \textbf{modello matematico} è la descrizione di un sistema che permette di determinare i segnali delle uscite noti gli ingressi e le condizioni iniziali. Distinguiamo tra sistemi multivariabili (MIMO) e scalari (SISO). Un sistema è detto \textbf{statico} quando l'uscita al tempo $t$ dipende esclusivamente dall'ingresso al medesimo tempo $t$. Un \textbf{sistema dinamico}, invece, ha uscita dipendente dal segnale di ingresso sull'intervallo $(-\infty , t]$, e ha quindi memoria. Per questi ultimi sistemi introduciamo i concetti di sistema in quiete (\textit{equilibrio}) e sistema in condizioni asintotiche(\textit{stazionarie}). 
\subsection{Insieme dei behavior}
Definiamo ora l'\textbf{insieme dei behavior} $\mathcal{B}$ come l'insieme di tutte le possibili coppie causa-effetto associate ad un sistema.
\begin{displaymath}
    \mathcal{B}:={\left( u(t), y(t) \right) : y(t)}
\end{displaymath}
è l'uscita del sistema corrispondente all'ingresso $u(t)$, con $u(t)$ e $y(t)$ che tipicamente appartengono agli spazi funzionali delle funzioni continue o differenziabili a tratti. 
Un sistema è \textbf{lineare} se soddisfa la proprietà di sovrapposizione degli effetti. 
\begin{displaymath}
    \forall (u_1,y_1), (u_2, y_2) \in \mathcal{B}, \forall \alpha_1,\alpha_2 \in \mathcal{R} \rightarrow \alpha_1(u_1,y_1)+\alpha_2(u_2, y_2) := (\alpha_1 u_1+ \alpha_2 u_2, \alpha_1y_1 + \alpha_2 y_2) \in \mathcal{B}
\end{displaymath}
Con \textbf{stazionario} intendiamo un sistema invariante nel tempo, ossia:
\begin{displaymath}
    \left(u(t), y(t)\right) \in \mathcal{B} \rightarrow \left(u(t-T), y(t-T)\right) \in \mathcal{B}
\end{displaymath}
\subsection{Controllo ad azione diretta e retroazione}
Vi è, tra le tipologie di controllo, una distinzione importantissima: quella tra i controlli \textbf{ad azione diretta} e quelli \textbf{in retroazione}. 
Nel primo, l'azione di comando dipende da: obiettivo perseguito, informazioni sul modello del sistema controllato, ingressi agenti sul sistema controllato. Nel secondo, oltre ai suddetti, vi è l'intervento della \textbf{variabile controllata}. In altri termini, l'ingresso dipende anche dall'uscita. Introduciamo poi anche i controlli feedforward/feedback a due/tre gradi di libertà. 
È utile notare come in sistemi disturbati, in cui cioè abbiamo una perturbazione data dal sistema stesso, il controllo ad azione diretta non la smorza, mentre quello in retroazione riduce l'errore di svariati ordini di grandezza. Bisogna però portare attenzione ai \textbf{fenomeni di instabilità} che nascono all'aumentare del guadagno di anello. 
\section{Modellistica ed equazioni differenziali lineari}
\subsection{Cenni di modellistica}
La \textbf{modellistica} è la costruzione dei modelli matematici dei sistemi, a partire da leggi fondamentali o dati sperimentali.
\subsubsection{Circuiti elettrici}
Citiamo anzitutto alcuni esempi elettrici di leggi fondamentali:\\
\begin{center}
Resistenza: $v_R = Ri$\\
Induttanza: $v_L=L\frac{di}{dt} = LDi$\\
Capacità: $v_c = \frac{Q}{C} = \frac{1}{C} \int_{-\infty}^t i(\tau)d\tau \rightarrow Dv_c = \frac{i}{C}$\\
\end{center}

Un circuito RLC diventa quindi
\begin{displaymath}
    v_i=v_L+v_R+v_c\\
    v_i(t) = LDi(t) + Ri(t)+ \frac{1}{C} \int_{-\infty}^t i(\tau)d\tau
\end{displaymath}
Calcoliamo quindi l'equazione differenziale lineare a coefficienti costanti:
\begin{displaymath}
    LD^2i+RDi+\frac{1}{C}i = Dv_i
\end{displaymath}
Costruiamo il modello matematico orientato da $v_i$ a $v_u$.
\begin{displaymath}
    LCD^2 v_u + RCDv_u + v_u = v_i
\end{displaymath}
\subsubsection{Sistemi meccanici}
Citiamo ora tre sistemi meccanici e le rispettive leggi del moto.
\begin{center}
    Massa: $MD^2x(t) = f_1(t) - f_2(t)$\\
    Molla: $f(t)=K(x_1(t)-x_2(t))$\\
    Ammortizzatore: $f(t) = B(v_1(t)-v_2(t)) \hspace{20px} f(t) = BD(x_1(t)-x_2(t))$
\end{center}
Introduciamo un sistema meccanico vibrante composto dai tre elementi, che avrà quindi equazione da f a x:
\begin{displaymath}
    mD^2 x(t) + bDx(t) + kx(t) = f(t)
\end{displaymath}
Otteniamo l'equazione differenziale
\begin{displaymath}
    mD^2y+bDy+ky = Df
\end{displaymath}
\subsubsection{OP-AMP}
Citiamo anche i circuiti elettrici con OP-AMP, deducendo 
\begin{displaymath}
    R_1CDy + y = -R_2CDu-u
\end{displaymath}
\subsection{Equazioni differenziali lineari}
Le equazioni differenziali lineari a coefficienti costanti possono rappresentare quindi sistemi scalari, generalizzando così:
\begin{displaymath}
    \sum_{i=0}^n a_i D^i y = \sum_{i=0}^m b_i D^i u
\end{displaymath}
Otteniamo così un modello matematico formale del sistema dinamico (orientato) $\Sigma, y =$ variabile d'uscita, $u=$ variabile d'ingresso, $a_n \neq 0, b_m \neq 0$. $n$ è l'ordine dell'eq. differenziale per estensione ordine di $\Sigma$, $n\ge m$; $\rho := n-m$ ordine relativo o grado relativo di $\Sigma$.
Ricollegandoci al concetto di \textbf{insieme dei behaviors} $\mathcal{B}$ di $\Sigma$, la coppia di segnali $\mathcal{B} := \{\left(u(t), y(t)\right)$ soddisfa l'equazione differenziale se $u(t)$ e $y(t)$ sono derivabili tante volte quanto necessario. 
\subsubsection{Proprietà del sistema}
Citiamo allora alcune proprietà del sistema. Per le dimostrazioni riferirsi alle slide.
\begin{itemize}
    \item Il sistema è lineare.
    \item Il sistema è stazionario.
\end{itemize}
\subsection{Determinazione dei segnali di uscita}
Una volta introdotto il sistema, sorge spontaneo un dubbio fondamentale:
\begin{center}
    \textbf{Noto il segnale di ingresso $u(t)|_{[0, +\infty]}$ e le condizioni iniziali $y(0), Dy(0),...,D^{n-1}y(0)$ determinare il segnale di uscita $y(t)|_{[0, +\infty]}$}
\end{center}
Se avessimo un'equazione omogenea, la soluzione sarebbe immediata. Ma spesso non è così, e ci serve un metodo generale per poter trattare le diverse casistiche. 
La classe dei segnali che utilizzeremo è $C_p^\infty$, insieme delle funzioni infinitamente derivabili a tratti. 
\begin{center}
    \textit{Una funzione appartiene a $C_p^\infty$ se esiste un insieme sparso $\mathcal{S}$ per il quale $f \in C^\infty (\mathbb{R}/S, \mathbb{R})$ e per ogni $n \in \mathbb{N}$ e per ogni $t \in \mathcal{S}$ i limiti $f^{(n)}(t^-)$ e $f^{(n)}(t^+)$ esistono e sono finiti. Quando $f$ è definita in $t \in \mathcal{S}$, convenzionalmente $f(t) := f(t^+)$. In particolare $C^{-1} := C_p^\infty (\mathbb{R})$ definisce l'insieme delle funzioni di classe $C^\infty$ a tratti definite su tutto $\mathbb{R}$}
\end{center}
\subsubsection{Proprietà di $C_p^\infty$}
In generale, sappiamo che $C^k \not\subset C^\infty_p$ e che $C_p^{k,\infty} := C^k \cap C^\infty_p$.
\subsubsection{Grado di continuità di una funzione o segnale}
Definiamo il grado di continuità di una funzione o segnale:
\begin{center}
    \textit{Se $f \in C_p^{k,\infty}, k $ è il grado di continuità di $f$.}
\end{center}
\begin{displaymath}
    \overline{C_p^{k,\infty}} := \left\{ f:\mathbb{R} \rightarrow \mathbb{R}:f \in C_p^{k, \infty}  \wedge f \not\in C_p^{k+1,\infty}\right\}
\end{displaymath}
Se $f \in \overline{C_p^{k,\infty}}$ allora $k$ è il grado massimo di continuità di $f$.
\subsubsection{Trasformate di Laplace}
Il metodo generale proposto per "integrare" l'equazione differenziale di $\Sigma$ si basa sulla \textbf{trasformata di Laplace}, che permette di trasformare un'equazione differenziale in un'equazione algebrica.
\section{Cenni di analisi complessa}
\subsection{Limite di una funzione complessa}
Consideriamo una funzione complessa di variabile complessa $f: \mathbb{C} \rightarrow \mathbb{C} s \rightarrow f(s)$. Se $s = \sigma + j \omega$, allora $f(s) = u(\sigma, \omega)+ jv(\sigma, \omega)$. Definiamo il limite $lim_{s\rightarrow s_0} f(s) = \lambda$ con la classica definizione da Analisi 1:
\begin{center}
    $\forall \epsilon >0, \exists \rho >0$ tale che se $s$ soddisfa $0<|s-s_0|<\rho \rightarrow |f(s) - \lambda| < \epsilon$
\end{center}
\subsubsection{Altre proprietà derivate}
Data questa definizione, possiamo definire altre proprietà, come la \textbf{continuità}: $f$ è continua in $s=s_0$ se $lim_{s\rightarrow s_0} f(s) = f(s_0)$. Da qui, $f(s)$ è continua in $s_0 = \sigma_0 + j\omega_0$ sse le funzioni reali $u(\sigma, \omega), v(\sigma, \omega)$ sono continue in $(\sigma_0, \omega_0)$. Definiamo poi la \textbf{derivabilità}: $f(s)$ è derivabile in $s=s_0$ se esiste il limite 
\begin{displaymath}
    lim_{\Delta s\rightarrow 0} \frac{f(s_0 + \Delta s) - f(s_0)}{\Delta s}
\end{displaymath}
Le regole base di derivabilità dell'analisi rimangono valide. Definiamo l'\textbf{analiticità}, ossia, $f(s)$ è analitica/olomorfa in $s=s_0$ se $f(s)$ è derivabile su di un intorno aperto contenente $s_0$. 
Infine, definiamo le \textbf{condizioni di Cauchy-Riemann}: $u(\sigma, \omega), v(\sigma, \omega)$ soddisfano le condizioni di Cauchy-Riemann se 
\begin{displaymath}
    \begin{cases} 
        \frac{\partial u}{\partial \sigma} = \frac{\partial v}{\partial \omega} \\ \frac{\partial u}{\partial \omega} = - \frac{\partial v}{\partial \sigma}
    \end{cases}
\end{displaymath}
\paragraph{Teorema}
Sia $f(s) = u(s) + jv(s)$:
\begin{enumerate}
    \item Se esiste $f^{(1)} (s_0)$ con $s_0 = \sigma_0 + j\omega_0$ allora esistono le derivate parziali di $u(\sigma, \omega), v(\sigma, \omega)$ in $(\sigma_0, \omega_0)$ e soddisfano le equazioni di Cauchy-Riemann
    \item Se $u(\sigma, \omega), v(\sigma, \omega)$ e le loro derivate parziali sono continue in $(\sigma_0, \omega_0)$ e soddisfano le condizioni di Cauchy-Riemann, allora esiste $f^{(1)} (s_0)$ con $s_0 = \sigma_0 + j\omega_0$
\end{enumerate}
\paragraph{Corollario}
Sia $f(s) = u(s) + jv(s)$ con $u(\sigma, \omega), v(\sigma, \omega)$ e le loro derivate parziali continue su di un dominio aperto $U \subseteq C$. Allora $f(s)$ è analitica su $U$ se e solo se $u(\sigma, \omega), v(\sigma, \omega)$ soddisfano, su U, le condizioni di Cauchy-Riemann. 
\paragraph{Teorema} 
Sia $f(s)$ analitica su di una regione aperta $U \subseteq C$. Allora la derivata $Df(s)$ è anch'essa una funzione analitica su $U$.
\paragraph{Corollario}
Se $f(s)$ è analitica sulla regione aperta $U$, allora $f(s)$ è ivi derivabile indefinitivamente.
\subsection{Integrali di linea nel piano complesso}
Definiamo innanzitutto l'\textbf{integrale}: data una funzione $f(s)$ ed una curva $\Gamma$ su $\mathbb{C}$ percorsa da $s_a$ a $s_b$, definiamo $\int_\Gamma f(s) ds \triangleq lim_{n\rightarrow \infty} \sum_{i=1}^n f(s_i)(s_i- s_{i-1})$ dove $s_0,...,s_n$ è una discretizzazione uniforme della curva $\Gamma$. 
\subsubsection{Calcolo dell'integrale di linea}
Sia $\Gamma$ una curva parametrica di classe $C^1$.
\begin{displaymath}
    \int_\Gamma f(s) ds = \int_a^b f\left(\Gamma(u) \right) \frac{d\Gamma}{du} du
\end{displaymath}

Definiamo una \textbf{curva chiusa semplice} come una curva continua tale che $\Gamma(a)=\Gamma(b)$ e $\Gamma(u_1) \neq \Gamma(u_2) \forall u_1 \neq u_2 \in (a,b)$
Il \textbf{teorema di Jordan} afferma che se $\Gamma$ è una curva chiusa semplice in $\mathbb{C}$ questa suddivide il piano complesso in due regioni distinte, una esterna e una interna. 
Definiamo un \textbf{insieme connesso} se per ogni coppia di punti appartenenti all'insieme esiste una curva continua $\Gamma$ che li congiunge tutta contenuta in R. È invece detto \textbf{semplicemente connesso} se è connesso e per ogni curva chiusa semplice $\Gamma$ appartenente all'insieme la regione interna di $\Gamma$ è tutta contenuta in R.
\paragraph{Teorema dell'integrale di Cauchy}
Sia $f(s)$ una funzione analitica su di una regione aperta e semplicemente connessa $U$ e $\Gamma$ una curva semplice ivi contenuta. Allora $\oint_\Gamma f(s) ds = 0$. 
\paragraph{Corollario}
Sia $f(s)$ una funzione analitica su di una regione aperta e semplicemente connessa $U$ e $\Gamma$ una curva ivi contenuta che congiunge $s_a$ ad $s_b$. Allora l'integrale di linea $\int_\Gamma f(s)ds$ non dipende dal percorso $\Gamma$ ma solo da $s_a, s_b$ e $f(s)$:
\begin{displaymath}
    \int_\Gamma f(s)ds = \int_{s_a}^{s_b} f(s)ds
\end{displaymath}
\paragraph{Teorema - Sviluppo in serie di Taylor}
Sia $f(s)$ una funzione analitica su di un cerchio $B(s_0, r_0)$ centrato su $s_0$ e con raggio $r_0$. Allora $\forall s \in B(s_0, r_0)$ 
\begin{displaymath}
    f(s) = \sum_{i=0}^\infty c_i (s-s_0)^i
\end{displaymath}
dove 
\begin{displaymath}
    c_i = \frac{f^{(i) (s_0)}}{i!} = \frac{1}{2\pi j}\oint \frac{f(s)}{(s-s_0)^{i+1}}ds
\end{displaymath}
Come corollario, otteniamo la \textbf{formula integrale di Cauchy}
\begin{displaymath}
    f(s_0) = \frac{1}{2\pi j} \oint_\Gamma \frac{f(s)}{s-s_0} ds
\end{displaymath}
\paragraph{Teorema - Sviluppo in serie di Laurent}
Sia $f(s)$ una funzione analitica sul cerchio $B(s_0, r_0)$ ad eccezione del suo centro $s_0$. Allora $\forall s \in B(s_0, r_0)- \{s_0\}$
\begin{displaymath}
    f(s) = \sum_{i=-\infty}^{+\infty} c_i(s-s_0)^i
\end{displaymath}
dove 
\begin{displaymath}
    c_i = \frac{f^{(i) (s_0)}}{i!} = \frac{1}{2\pi j}\oint \frac{f(s)}{(s-s_0)^{i+1}}ds
\end{displaymath}
\subsection{Classificazione del punto isolato $s_0$}
Se $c_i =0 \forall i \in \mathbb{Z}^-$ definendo $f(s_0) = c_0$ risulta $f(s)$ analitica in $s=s_0$. Se $c_i \neq 0$ per qualche $i \in \mathbb{Z}^-$, $s_0$ è una singolarità di $f(s)$, detta \textbf{singolarità polo} quando i $c_i \neq 0$ sono in numero finito, con $-n = min\{i\in \mathbb{Z}^-: c_i \neq 0\}$ $s_0$ è polo di ordine $n$. Invece abbiamo una \textbf{singolarità essenziale} quando i $c_i \neq 0$ con $i \in \mathbb{Z}^-$ sono infiniti. Se abbiamo una $f(s)$ analitica in $B(s_0, r_0) - \{s_0\}$, $s_0$ è una singolarità di $f(s)$ se e solo se $f(s)$ assume valori illimitati in un intorno di $s_0$. 
Il \textbf{Teorema di Picard} afferma che se abbiamo $s_0$ singolarità essenziale di $f(s)$, in ogni intorno di $s_0$ la funzione $f(s)$ assume ogni valore complesso infinite volte con l'eventuale eccezione di un solo particolare valore. 
\subsubsection{Residui}
Data una singolarità $s_0$, definiamo il \textbf{residuo} come il coefficiente $c_{-1}$ dello sviluppo in serie di Laurent.
\paragraph{Teorema dei residui di Cauchy}
Sia $\Gamma$ una curva chiusa semplice e $f(s)$ una funzione analitica su $\Gamma$ e nella sua regione interna ad eccezione dei punti singolari $s_1,...,s_n$ in essa contenuti, allora 
\begin{displaymath}
    \oint_\Gamma f(s) ds = 2\pi j \sum_{i=1}^n Res\{f, s_i\}
\end{displaymath}
\subsubsection{Poli e zeri}
Sia $s_0$ una singolarità polo di $f(s)$. Allora $s_0$ è polo di ordine $n$ sse esiste $g(s)$ analitica in $s_0$ con $g(s_0) \neq 0$ tale che 
\begin{displaymath}
    f(s) = \frac{g(s)}{(s-s_0)^n}
\end{displaymath}
Sia $f(s)$ analitica in $z$. $z$ è detto \textbf{zero} di $f$ se $f(z)=0$. Considerato lo sviluppo di Taylor $f(s)= c_1(s-z)+\dots$ ed $n:=min\{i \in \mathbb{N}: c_i \neq 0\}$, $z$ è detto zero di ordine $n$ di $f(s)$. È detto tale se e solo se esiste $g(s)$ analitica in $z$ con $g(z) \neq 0$ tale che $f(s) = (s-z)^n g(s)$. Ricaviamo un'ultima proprietà: se $f: \mathbb{C} \rightarrow \mathbb{C}$ ha una singolarità polare in $p$ di ordine $n$ allora 
\begin{displaymath}
    Res\{f,p\} = \frac{1}{(n-1)!} D^{n-1} \left(f(s)(s-p)^n\right)|_{s=p}
\end{displaymath}
\subsection{Continuazione analitica}
Data una funzione $f(s)$ definita da uno sviluppo in serie di Taylor su di un cerchio $B_0(s_0, r_0)$ è possibile estendere/continuare la definizione di $f(s)$ all'esterno di $B_0$ mediante lo sviluppo in serie di Taylor di altri punti di $B_0$. Il procedimento è ricorsivo. Possono anche emergere funzioni a più valori!
\section{La trasformata di Laplace}
La \textbf{trasformata di Laplace} è un operatore funzionale che converte un'equazione differenziale in un'equazione algebrica, permettendo di risolvere anche equazioni differenziali lineari con condizioni iniziali arbitrarie.
Permette inoltre di analizzare i fenomeni transitori ed asintotici di una grande varietà di sistemi. 
Si applica ad una funzione $f$ di variabile reale con codominio $\mathbb{R}$ o $\mathbb{C}$. Assumiamo ora $f \in \mathbb{C}_p^\infty (\mathbb{R})$, sappiamo che $\exists \sigma \in \mathbb{R}$ per il quale $\int_0^{+\infty} |f(t)| e^{-\sigma t} dt < + \infty$. Se vale quest'ultima condizione, allora $\forall \sigma_1 > \sigma : \int_0^{+\infty} |f(t)| e^{-\sigma_1 t} dt < + \infty$. Definiamo l'\textbf{ascissa di convergenza} di $f(t)$ come $\sigma_c := inf \left\{\sigma \in \mathbb{R} : \int_0^{+\infty}|f(t)| e^{- \sigma t} dt\right\}$ Spesso assumeremo $f(t) = 0$ per $t<0$. 
Volendo ora dare una definizione rigorosa della trasformata, 
\begin{center}
    La trasformata di Laplace di un segnale (funzione) $f(t)$ è la funzione $F(s) = \mathcal{L}[f(t)]$ definita da
    \begin{displaymath}
        F(s) = \int_0^{+\infty} f(t) e^{-st} dt
    \end{displaymath}
    per i valori $s\in \mathbb{C}$ per i quali l'integrale converge.
\end{center}
Notiamo alcune cose:
\begin{itemize}
    \item $F$ è una funzione complessa di variabile complessa, $\mathcal{L}[\dot]$ indica l'operatore di Laplace.
    \item La notazione usuale prevede che le lettere minuscole denotino segnali e funzioni, le corrispondenti maiuscole le loro trasformate.
\end{itemize}
\subsection{Proprietà della trasformata}
\subsubsection{Analitica}
La trasformata $F(s)$ è una funzione analitica sul semipiano $\left\{s \in \mathbb{C}: Re s > \sigma_c\right\}$
\subsubsection{Coniugato}
Denotando il coniugato con $\overline{ }$, $\overline{F(s)} = F(\overline{s})$
\subsubsection{Linearità}
La trasformata di Laplace è un operatore lineare: per ogni segnale $f_1(t)$ e $f_2(t)$ e per ogni scalare $c_1$ e $c_2$:
\begin{displaymath}
    \mathcal{L}[c_1 f_1 (t) + c_2f_2(t)] = c_1 \mathcal{L}[f_1(t)] + c_2 \mathcal{L}[f_2(t)]
\end{displaymath}
\subsubsection{Iniettività}
La trasformata di Laplace è \textbf{iniettiva}:
\begin{displaymath}
    \mathcal{L}[f(t)] = \mathcal{L}[g(t)] \rightarrow f(t) = g(t) \textrm{ su }[0, +\infty )
\end{displaymath}
È quindi ben definita la trasformata inversa.
\subsection{La trasformata inversa di Laplace}
Sia $F(s) = \mathcal{L}[f(t)]$ allora, per ogni $\sigma_0 > \sigma_c$
\begin{displaymath}
    \mathcal{L}^{-1} \rightarrow f(t) = \frac{1}{2\pi j} \int_{\sigma_0-j\infty}^{\sigma_0+j\infty} F(s) e^{st} ds
\end{displaymath}
\subsection{Trasformate notevoli}
\subsubsection{Trasformata della derivata}
Sia $f \in C^1 (\mathbb{R}_{>0})$ segue
\begin{displaymath}
    \mathcal{L}[Df(t)] = sF(s) - f(0+)
\end{displaymath}
Generalizzando per gli ordini superiori, otteniamo
\begin{displaymath}
    \mathcal{L}[D^i f] = s^i F(s) - \sum_{j=0}^{i-1} s^j D^{i-1-j} f_+
\end{displaymath}
\subsubsection{Trasformata dell'integrale}
\begin{displaymath}
    \mathcal{L}\left[\int_0^t f(v) dv\right] = \frac{1}{s} F(s)
\end{displaymath}
\subsection{Teoremi e gotchas}
\subsubsection{Teorema del valore finale}
Sia $f\in C^1 (\mathbb{R}_+)$ con $f$ e $Df$ aventi ascisse di convergenza non positive. Se esiste il limite $lim_{t\rightarrow+\infty} f(t)$ vale
\begin{displaymath}
    lim_{t\rightarrow+\infty} f(t) = lim_{s\rightarrow0} sF(s)
\end{displaymath}
\subsubsection{Teorema del valore iniziale}
Sia $f\in C^1 (\mathbb{R}_+)$. Se esiste il limite $lim_{s\rightarrow+\infty} sF(s)$ vale
\begin{displaymath}
    f(0+)=lim_{s\rightarrow+\infty} sF(s)
\end{displaymath}
\subsubsection{Traslazione nel tempo}
Per ogni $t_0 \ge 0$ vale 
\begin{displaymath}
    \mathcal{L}[f(t-t_0)\cdot 1(t-t_0)]= e^{-t_0s}F(s)
\end{displaymath}
\subsubsection{Traslazione nella variabile complessa $s$}
Per ogni $a \in \mathbb{R}(\mathbb{C})$ vale 
\begin{displaymath}
    \mathcal{L}[e^{\alpha t} f(t)] = F(s-a)
\end{displaymath}
\subsubsection{Teorema di convoluzione}
Si abbia $f(t) = g(t)=0$ per $t<0$. La convoluzione dei segnali $f$ e $g$, spesso indicata come $f*g$, è il segnale 
\begin{displaymath}
    \int_0^t f(v)g(t-v)dv
\end{displaymath}
rappresentabile anche come $f*g=g*f$
\begin{displaymath}
    \int_0^t g(v) f(t-v) dv
\end{displaymath}
La trasformata della convoluzione è 
\begin{displaymath}
    \mathcal{L}\left[    \int_0^t f(v)g(t-v)dv\right] = F(s)G(s)
\end{displaymath}
\subsection{Antitrasformazione di funzioni razionali}
Per antitrasformare le funzioni razionali, sfruttiamo il \textbf{metodo dei fratti semplici}, ossia scomponiamo il denominatore in poli semplici e poi cerchiamo i $k_i$:
\begin{displaymath}
    F(s) = \frac{k_1}{(s-p_1)}+\frac{k_2}{(s-p_2)}+...+\frac{k_n}{(s-p_n)}
\end{displaymath}
Con i $k_i$ rappresentanti il residuo di $F(s)$ in $p_i$, e pari a
\begin{displaymath}
    k_i= (s-p_i)F(s)|_{s=p_i}
\end{displaymath}
Ottenendo
\begin{displaymath}
    f(t) = \sum_{i=1}^n k_i e^{p_it}
\end{displaymath}
\subsection{Trasformate notevoli}
Citiamo infine altre due trasformate notevoli:
\begin{displaymath}
    \mathcal{L}[t^n] = \frac{n!}{s^{n+1}} \hspace{10px} \mathcal{L}[e^{\alpha t}] = \frac{1}{s-a}
\end{displaymath}
\section{Le funzioni impulsive e l'insieme dei behaviors}
Consideriamo anzitutto un sistema dinamico $\Sigma$ descritto da $Dy(t) + 2y(t) = 2Du(t)+2u(t)$ ed assumiamo che per i tempi negativi sia $y(t) = e^{-2t}$ e $u(t)=0$ con $t<0$.
Questa coppia di funzioni soddisfa l'eq. differenziale 
\begin{displaymath}
    Dy(t) = -2e^{-2t} \rightarrow (-2e^{-2t}) + 2(e^{-2t}) = 0 \forall t<0
\end{displaymath}
Quindi:
\begin{displaymath}
    \left(0, e^{-2t}\right)|_{(-\infty, 0)} \in \mathcal{B}
\end{displaymath}
Introduciamo ora nel sistema una azione forzante $u(t) = 1$ per $t \ge 0$. Quindi $u(t) = 1(t) \forall t \in \mathbb{R}$. Vogliamo determinare $y(t)$ per $t \ge 0$. Non possiamo però definire l'insieme dei behaviors eseguendo la trasformata di Laplace sull'equazione differenziale: otterremmo una soluzione valida per qualsiasi valore del parametro $y_+$, che sarebbe assurdo. L'insieme dei behaviors \textbf{errato} che si genera sarebbe così fatto:
\begin{displaymath}
    \mathcal{B}= \left\{\left(u(t), y(t)\right) \in C^\infty_p (\mathbb{R})^2 : Dy+ 2y = 2Du +2u \forall t \in \mathbb{R}-\left\{t_1,t_2,...\right\}\right\}
\end{displaymath}
Osserviamo però, che dato $C^{1, \infty}_p = C^1 \cap C_p^\infty$: 
\begin{displaymath}
    \left\{\left(u(t), y(t)\right) \in (C_p^{1,\infty})^2 : Dy + 2y = 2Du + 2u \forall t \in \mathbb{R}\right\} \subset \mathcal{B}
\end{displaymath}
Per risolvere l'impasse, definiamo l'azione forzante come 
\begin{displaymath}
    u(t) :=
    \begin{cases}
        0 \textrm{ per }t<0\\
        3\frac{t^2}{\tau^2}- 2\frac{t^3}{\tau^3} \textrm{ per }t \in [0, \tau)\\
        1 \textrm{ per } t \ge \tau
    \end{cases}
    \rightarrow u(t) \in C_p^{1,\infty} \forall \tau > 0
\end{displaymath}
Assumendo $y(t) \in C_p^\infty$ segue $y(0-) = y(0+) = 1$. Possiamo quindi determinare $y(t)$ con le condizioni iniziali al tempo $0+$: $u(0+)=0$ e $y(0+)=1$.
Portando $\tau \rightarrow 0+$ otteniamo la soluzione desiderata. Ma se la volessimo senza dover applicare tutte le volte questo metodo di smoothing?
Osserviamo che quando $\tau \rightarrow 0+$, $Du(t)$ in un intorno dell'origine diverge all'infinito. $Du(t) = 6\frac{t}{\tau^2} - 6\frac{t^2}{\tau^3}$ per $t \in [0, \tau] \rightarrow max_{t \in [0, \tau]} Du(t) = Du(t)|_{t=\frac{\tau}{2}}=\frac{3}{2\tau}$.
Insomma, $Du(t)$ converge ad una funzione impulsiva (distribuzione) detta \textbf{delta di Dirac $\delta(t)$}.
\subsection{Cenni di teoria delle funzioni impulsive}
La funzione impulsiva più semplice è il gradino unitario $1(t)$:
\begin{displaymath}
    1(t) := \begin{cases}
        0 \textrm{ per }t<0\\
        1 \textrm{ per }t\ge0
    \end{cases}
\end{displaymath}
Introduciamo $f(t<\tau) \in C_p^{0,\infty}$:
\begin{displaymath}
    f(t:\tau) :=
    \begin{cases}
        0 \textrm{ per } t<0\\
        \frac{1}{\tau} t \textrm{ per }0\le \le \tau\\
        1 \textrm{ per }t>\tau
    \end{cases}
\end{displaymath}
$lim_{\tau \rightarrow 0+} f(t:\tau) = 1(t)$.
La derivata di questa funzione sarà ovviamente pari a 0 per $t<0$ e $t\ge\tau$:
\begin{displaymath}
    Df(t;\tau) = 
    \begin{cases}
        0 \textrm{ per } t<0\\
        \frac{1}{\tau} \textrm{ per } 0\le t \le \tau\\
        0 \textrm{ per }t\ge\tau
    \end{cases}
\end{displaymath}
Notiamo altresì che $lim_{\tau\rightarrow 0+} Df(t;\tau)$ è proprio la delta di Dirac!
$\delta(t)$ è una distribuzione, o, più informalmente, una funzione impulsiva. È la \textbf{derivata generalizzata} del gradino unitario $\delta(t) := D^*1(t)$. $D^*$ è proprio l'operatore della derivata generalizzata: è un operatore lineare come $D$. Più precisamente, $D^*$ è la derivata in senso distribuzionale. Sappiamo inoltre che, assumendo $t_a < T < t_b$ 
\begin{displaymath}
    \int_{t_a}^{t_b} \delta(t-T)dt = 1 \hspace{10px} \int_{t_a}^{t_b} f(t)\delta(t-T)dt = f(T) 
\end{displaymath}
Introduciamo le derivate generalizzate di $\delta(t)$:
\begin{displaymath}
    D^{*i}\delta(t) \textrm{è la derivata generalizzata di ordine i della delta } =: \delta^{(i)}(t)
\end{displaymath}
Possiamo costruire $\delta^{(1)}(t)$ mediante limite di una funzione continua a tratti:
\begin{displaymath}
    1(t) = lim_{\tau\rightarrow0+}f(t;\tau) \hspace{10px} \delta(t):= D^* 1(t) = lim_{\tau\rightarrow0+} Df(t;\tau)
\end{displaymath}
\begin{displaymath}
    \delta^{(1)} (t) := D^* \delta(t) = lim_{\tau\rightarrow0+}D^2 f(t;\tau)
\end{displaymath}

Questo metodo si può estendere per mostrare il significato di $\delta^{(i)} (t), i>1$.
\subsection{Derivate generalizzate di una funzione discontinua}
Ipotizziamo $f \in C_p^\infty(\mathbb{R})$ e sia $t=0$ l'unico istante di discontinuità:
\begin{displaymath}
    g(t) := \begin{cases}
        f(t) \textrm{ per } t<0\\
        f(t)-(f_+ - f_-) \textrm{ per }t\ge0
    \end{cases}
    g(t) \in C_p^{0, \infty}
\end{displaymath}
Ottenendo
\begin{displaymath}
    g(t) = f(t) - (f_+ - f_-)1(t)
\end{displaymath}
ovvero, una funzione discontinua è pari a una funzione continua $+$ una funzione a gradino.
Derivando in senso usuale otteniamo $Df(t) = Dg(t) \forall t \neq 0$. Assumiamo ora che la derivata generalizzata di una funzione continua sia $D^* g(t) := Dg(t^+)$. Applicando l'operatore $D^*$ otteniamo
\begin{displaymath}
    D^* f(t) = Df(t^+) + (f_+ - f_-)\delta(t)
\end{displaymath}
Ossia, derivata gen. di ordine 1 $=$ funzione discontinua $+$ funzione impulsiva (di ordine 0). La funzione discontinua $Df(t^+)$ può essere scomposta nella somma di una funzione continua più una funzione a gradino:
\begin{center}
    derivata gen. di ordine 1 $=$ f. continua $+$ f. a gradino $+$ f. impulsiva di ordine 0. 
\end{center}
Applicando la derivata generalizzata alla relazione che esprime $D^*f(t)$, otteniamo
\begin{displaymath}
    D^{*2} f(t) = Dg_1(t^+) + (Df_+ - Df_-)\delta(t) + (f_+ - f_-)\delta^{(1)}(t)
\end{displaymath}
Iterando il tutto per generalizzare, otterremo 
\begin{displaymath}
    D^{*n} f(t) = D^n f(t^+) + (D^{n-1} f_+ - D^{n-1} f_-) \delta(t)+...+(f_+ - f_-)\delta^{(n-1)}(t)
\end{displaymath}
Che, con $t<0$ o $t>0$ è $D^{*n} f(t) = D^n f(t)$, mentre con $t=0$ è $D^{*n} f(0) = (D^{n-1} f_+ - D^{n-1} f_-) \delta(0) + ... + (f_+-f_-)\delta^{(n-1)}(0)$.
Più in generale: $f \in C_p^\infty (\mathbb{R})$ con $t_1,t_2,...$ istanti di possibile discontinuita:
\begin{displaymath}
D^{*n} f(t) = D^n f(t^+)+\end{displaymath}\begin{displaymath}
\left(D^{n-1}(t_1^+) - D^{n-1}(t_1^-)\right)\delta(t-t_1)+...+\left(f(t_1^+)-f(t_1^-)\right)\delta^{(n-1)}(t-t_1)+\end{displaymath}\begin{displaymath}
\left(D^{n-1}(t_2^+) - D^{n-1}(t_2^-)\right)\delta(t-t_2)+...+\left(f(t_2^+)-f(t_2^-)\right)\delta^{(n-1)}(t-t_2)+\dots
\end{displaymath}
\subsection{Principio di identità delle funzioni impulsive}
Le funzioni impulsive 
\begin{displaymath}
    c_{-1} + c_0 \delta(0) + c_1 \delta^{(1)}(0)+\dots+c_k\delta^{(k)}(0)
\end{displaymath}
e
\begin{displaymath}
    d_{-1} + d_0\delta(0)+d_1\delta^{(1)}(0)+\dots+d_k\delta^{(k)}(0)
\end{displaymath}
sono uguali fra loro sse $c_0=d_0,\dots,c_k=d_k$.
Ritornando all'esempio iniziale, quindi, l'eq. differenziale di $\Sigma$ interpretata in senso distribuzionale
\begin{displaymath}
    D^* y(t) + 2y(t) = 2D^* u(t) + 2u(t)
\end{displaymath}
deve essere soddisfatta per ogni $t \in \mathbb{R}$ compresi gli istanti di discontinuità.
\subsection{Insieme dei behaviors}
Dato un insieme dinamico $\Sigma$ descritto dall'eq. differenziale 
\begin{displaymath}
    \sum_{i=0}^n a_i D^i y = \sum_{i=0}^m b_i D^i u
\end{displaymath}
si definisce insieme dei behaviors di $\Sigma$
\begin{displaymath}
    \mathcal{B}:= \left\{(u,y)\in C_p^\infty (\mathbb{R})^2: \sum_{i=0}^n a_i D^{*i} y = \sum_{i=0}^m b_i D^{*i}u\right\}
\end{displaymath}
L'equazione differenziale è soddisfatta in senso distribuzionale per ogni $t \in \mathbb{R}$. Se abbiamo $t=0$ istante di discontinuità emergono le condizioni al tempo $0-$ e $0+$. Le relazioni fra i valori al tempo $0+$ ($y_-, Dy_-,\dots,D^{n-1}y_-; u_-\dots$) e quelli al tempo $0+$ ($y_+, Dy_+,\dots,D^{n+1}y_+; u_+\dots$) sono determinabili eguagliando le espressioni impulsive dell'eq. differenziale al tempo $t=0$.
\subsubsection{Proprietà}
Sia $\left(u(t),y(t)\right) \in \mathcal{B}$ con $u(t)$ funzione discontinua. Se $\rho=0$ allora anche l'uscita $y(t)$ è una funzione discontinua. Se $\rho\ge1$ allora $y(t) \in \overline{C_p^{\rho-1,\infty}}$.\\
Otteniamo anche una proprietà che definisce la relazione tra i gradi di continuità dell'ingresso e dell'uscita: sia $\left(u(t),y(t)\right) \in \mathcal{B}$ e $l \in \mathbb{N}$. Allora
\begin{displaymath}
    u(t)\in C_p^{l,\infty} \Leftrightarrow y(t)\in C_p^{\rho+l,\infty}, \hspace{10px}u(t)\in \overline{C_p^{l,\infty} }\Leftrightarrow y(t)\in \overline{C_p^{\rho+l,\infty}}
\end{displaymath}
\section{La funzione di trasferimento}
Definiamo anzitutto lo spazio delle sequenze impulsive $\mathcal{I}^*$:
\begin{displaymath}
    \mathcal{I}^* \triangleq \left\{d:\mathbb{R}\rightarrow\mathbb{R}^*:d(t) = \sum_{i=1}^{+\infty}\sum_{j=0}^{r_i} c_{ij}\delta^{(j)}(t-t_i), c_{ij} \in \mathbb{R}\right\}
\end{displaymath}
Estensione distribuzionale delle funzioni derivabili a tratti: $C_p^\infty (\mathbb{R})^* \triangleq C_p^\infty (\mathbb{R}) + \mathcal{I}^*$.
\subsection{La trasformata della derivata generalizzata}
Tenendo conto del solo istante di discontinuità in $t=0$, otteniamo, data $f \in C_p^{\infty} (\mathbb{R})(C_p^\infty(\mathbb{R})^*)$, segue
\begin{displaymath}
    \mathcal{L}[D^*f(t)] = sF(s) - f(0-)
\end{displaymath}
Per ottenere le derivate generalizzate di ordine superiore:
\begin{displaymath}
    \mathcal{L}[D^{*i}f] = s^i F(s) - s^{i-1}f_- - s^{i-2} Df_- -\dots-sD^{i-2}f_--D^{i-1}f_-
\end{displaymath}
\subsection{Estensione dell'insieme dei behaviors}
Dato un sistema dinamico $\Sigma$ descritto dall'eq. differenziale
\begin{displaymath}
    \sum_{i=0}^n a_i D^i  y = \sum_{i=0}^m b_i u
\end{displaymath}
si definisce estensione impulsiva dei behaviors o \textbf{behavior esteso}
\begin{displaymath}
    \mathcal{B}^* := \left\{(u,y) \in C_p^\infty (\mathbb{R})^* \times C_p^\infty (\mathbb{R})^* : \sum_{i=0}^n a_i D^{*i} y = \sum_{i=0}^m b_i D^{*i} u\right\}
\end{displaymath}
Ancora l'equazione differenziale è soddisfatta in senso distribuzionale per ogni $t \in \mathbb{R}$. 
\begin{displaymath}
    \mathcal{B} \subset \mathcal{B}^*
\end{displaymath}
\subsubsection{Proprietà}
\begin{itemize}
    \item Sia $(u,y)\in \mathcal{B}^*$, segue $(D^*u, D^*y)\in \mathcal{B}^*$.
    \item Proprietà della coppia azione forzante-risposta forzata: sia $(u,y) \in \mathcal{B}^*$ con $u(t)$ azione forzante e $y(t)$ risposta forzata. Segue 
    \begin{displaymath}
        \left(\int_{0-}^t u(v) dv,\int_{0-}^t y(v) dv\right) \in \mathcal{B}^*
    \end{displaymath}
\end{itemize}
\subsection{Il problema fondamentale dell'analisi del dominio nel tempo di un sistema $\Sigma$}
Note le condizioni iniziali al tempo $0-$  $y_-, Dy_-,...,D^{n-1}y_-$ e $u_-,Du_-,\dots,D^{m-1}u_-$ e l'azione forzante $u(t), t\ge0$, vogliamo determinare la risposta $y(t), t\ge0$.
Risolviamo quindi l'equazione differenziale di $\Sigma$
\begin{displaymath}
    \sum_{i=0}^n a_i D^{*i} y(t) = \sum_{i=0}^m b_i D^{*i} u(t)
\end{displaymath}
Applicando la trasformata di Laplace. Otterremmo una soluzione $y(t) = y_{for.}(t) + y_{lib.}(t), t\ge0$, ossia un'uscita composta da risposta forzata di $\Sigma$ all'azione forzante, e una risposta (evoluzione) libera di $\Sigma$.
\subsection{Funzione di trasferimento}
Definiamo ora la funzione di trasferimento di un sistema la funzione di variabile complessa $G(s)$ per la quale è valida la relazione
\begin{displaymath}
    \mathcal{L}[y(t)] = G(s)\mathcal{L}[u(t)]
\end{displaymath}
$\forall (u(t), y(t)) \in \mathcal{B}$ con $u(t)=0, y(t)=0$ per $t<0$.
Abbiamo quindi ottenuto un modello matematico alternativo all'eq. differenzialie:
\begin{displaymath}
    G(s)=\frac{\sum_{i=0}^m b_i s^i}{\sum_{i=0}^n a_i s^i}=\frac{b(s)}{a(s)}
\end{displaymath}
Se le condizioni iniziali sono tutte nulle (sistema in quiete per $0-$), $Y(s)=G(s)U(s)\rightarrow Y_{for.}(s)=G(s)U(s)$ (trasformata della risposta forzata). Sia $g(t):=\mathcal{L}^{-1} [G(s)]$ con $g(t)=0, t<0: g(t)$ è la \textbf{risposta all'impulso} a partire da una condizione di quiete $(\delta(t), g(t)) \in \mathcal{B}^*$. Dal teorema di convoluzione sappiamo che $y_{for.}(t) = \int_0^t g(t-v)u(v)dv$. Otteniamo quindi la \textbf{soluzione generale dell'equazione differenziale} ($t\ge0$):
\begin{displaymath}
    y(t)=\int_0^t g(t-v)u(v)dv + \mathcal{L}^{-1}\left[\frac{\sum_{i=1}^n \sum_{j=0}^{i-1}a_i D^{i-1-j}y_- s^j - \sum_{i=1}^{m} \sum_{j=0}^{i-1} b_i D^{i-1-j}u_- s^j}{\sum_{i=0}^n a_is^i}\right]
\end{displaymath}
\subsection{Definizioni}
\subsubsection{Proprio}
Un sistema $\Sigma$ si dice \textbf{(strettamente) proprio} se la sua funzione di trasferimento è \textbf{(strettamente) propria}. Quindi, con $n\ge m (\rho \ge 0)$ abbiamo $\Sigma$ proprio, se $n>m (\rho\ge1)$ strettamente proprio.
\subsubsection{Guadagno statico}
Definiamo il \textbf{guadagno statico di $\Sigma$} come il rapporto fra il valore costante dell'uscita e il valore costante dell'ingresso ($\neq 0$) quando $\Sigma$ è all'equilibrio:
\begin{displaymath}
    K := \frac{y_c}{u_c} \textrm{ con } (u_c, y_c) \in \mathcal{B} \textrm{ e }u_c \neq 0
\end{displaymath}
Dall'equazione differenziale otteniamo $K=\frac{b_0}{a_0} \rightarrow K=G(0)$.
\subsubsection{Polinomio caratteristico di $\Sigma$}
Dato il sistema $\Sigma$ descritto dall'eq. differenziale $\sum_{i=0}^n a_i D^i y = \sum_{i=0}^m b_i D^i u$, il polinomio $a(s)= \sum_{i=0}^n a_i s^i$ è detto polinomio caratteristico di $\Sigma$. È utile notare che esso è il polinomio a denominatore della funzione di trasferimento.
\subsubsection{Poli e zeri}
I poli e zeri di $\Sigma$ sono i poli e gli zeri della funzione di trasferimento. 
\subsubsection{Modi del sistema dinamico $\Sigma$}
I \textbf{modi} sono le funzioni  "tipiche" associate ai poli di $\Sigma$ secondo la regola:
\begin{center}
    Se $p$ è un polo reale di molteplicità $h$: $e^{pt}, te^{pt},\dots, t^{h-1}e^{pt}$
\end{center}
\begin{center}
    Se $\sigma+j\omega$ è una coppia di poli complessi coniugati di molteplicità $h$: $e^{\sigma t} sen(\omega t+\phi_1), te^{\sigma t} sen(\omega t+\phi_2),\dots, t^{h-1}e^{\sigma t} sen(\omega t+\phi_h)$ oppure equivalentemente $e^{\sigma t} sen(\omega t), e^{\sigma t} cos(\omega t), te^{\sigma t} sen(\omega t), te^{\sigma t} cos(\omega t),\dots, t^{h-1}e^{\sigma t} sen(\omega t), t^{h-1} e^{\sigma t} cos(\omega t)$
\end{center}

\subsubsection{Risposta libera e modi di $\Sigma$}
Sia $\Sigma$ un sistema per il quale i poli coincidono con le radici del polinomio caratteristico ($a(s)$ e $b(s)$ coprimi fra loro). Allora la risposta libera è una combinazione lineare dei suoi modi. 
\subsubsection{Razionalità}
Non tutti i sistemi dinamici lineari e stazionari sono caratterizzati da funzioni di trasferimento razionali. Un esempio è il ritardo finito.
\subsubsection{Segnali tipici per l'ingresso di $\Sigma$}
Alcuni segnali tipici di ingresso:
\begin{itemize}
    \item $\delta(t)$ impulso unitario (delta di Dirac): $\mathcal{L}[\delta (t)] = 1$
    \item $1(t)$ gradino unitario: $\mathcal{L}[1(t)] = \frac{1}{s}$
    \item $t\cdot 1(t)$ rampa unitaria: $\mathcal{L}[t\cdot 1(t)] = \frac{1}{s^2}$
    \item $\frac{1}{2}t^2 \cdot 1(t)$ parabola unitaria: $\mathcal{L}\left[\frac{1}{2}t^2 \cdot 1(t)\right] = \frac{1}{s^3}$
\end{itemize}
\subsubsection{Risposta canonica}
La risposta canonica è la risposta forzata di $\Sigma$ a un segnale tipico di ingresso. Quelle usualmente adottate sono $g(t)$, la risposta all'impulso, detta anche \textbf{risposta impulsiva}, e $g_s(t)$, la risposta al gradino $1(t)$ detta \textbf{risposta indiciale}. Sappiamo inoltre che 
\begin{displaymath}
    g(t) = \mathcal{L}^{-1}[G(s)] \hspace{10px} g_s(t) = \mathcal{L}^{-1}\left[\frac{1}{s}G(s)\right]
\end{displaymath}
Una proprietà interessante è che
\begin{displaymath}
    \int_{0-}^t g(v) dv = g_s(t) \hspace{10px} g(t)=D^* g_s (t)
\end{displaymath}
Per i sistemi strettamente propri, $g(t) = Dg_s(t^+)$.
\subsubsection{Integrali di Vaschy}
Nota la risposta al gradino $g_s(t)$, la risposta forzata $y_{for} (t), t\ge0$ effetto dell'azione forzante $u(t), t\ge0$ è determinabile come 
\begin{displaymath}
    y_{for}(t) = \int_0^t u' (v) g_s(t-v) dv + u(0+)g_s(t)
\end{displaymath}
\begin{displaymath}
    y_{for}(t) = \int_0^t  g_s(v) u'(t-v) dv + u(0+)g_s(t)
\end{displaymath}
\section{Sistemi dinamici elementari}
Con questa lezione ci poniamo due obiettivi: studiare le caratteristiche dei sistemi lineari più semplici (primo ordine con grado relativo uno e secondo ordine con grado relativo due) e semplificare i sistemi di più complessi comparandoli a sistemi di secondo ordine. 
\subsection{Sistemi del primo ordine (strettamente propri)}
Un sistema del primo ordine strettamente proprio è definito da $G(s)=\frac{1}{1+\tau s}$ (guadagno statico normalizzato a 1), equazione differenziale $\tau Dy + y = u$ con $\tau$ costante di tempo ($>0$). Ha un polo ($-\frac{1}{\tau}$) e un modo ($e^{-\frac{1}{\tau}t}$). Per determinare la risposta al gradino unitario $g_s(t)$ svolgiamo l'antitrasformata:
\begin{displaymath}
    g_s(t) = \mathcal{L}^{-1}\left[\frac{1}{1+\tau s}\frac{1}{s}\right] = 1 - e^{-t/\tau}, t\ge0
\end{displaymath}
\subsubsection{Parametri della risposta al gradino}
Spesso la risposta al gradino unitario di un sistema dinamico generico ha un andamento caratteristico, dove distinguiamo alcuni parametri:
\begin{itemize}
    \item $S$ massima sovraelongazione (in \% del valore di regime)
    \item $T_r$ tempo di ritardo
    \item $T_s$ tempo di salita
    \item $T_m$ istante di massima sovraelongazione 
    \item $T_a$ tempo di assestamento $inf\left\{T>0: |g_s(t)-y_{regime}|\le 0,05 y_{regime} \forall t \ge T\right\}$
\end{itemize}
\subsection{Sistemi del secondo ordine (senza zeri)}
La funzione di trasferimento $G(s)$ sia così parametrizzata:
\begin{displaymath}
    G(s)=\frac{\omega^2_n}{s^2+2\delta\omega_n s + \omega_n^2}, G(0)=1
\end{displaymath}
Con equazione differenziale
\begin{displaymath}
    D^2(y)+2\delta\omega_n Dy + \omega^2_n y = \omega_n^2 u
\end{displaymath}
dove $\omega_n$ è la pulsazione naturale, mentre $\delta$ è il coefficiente di smorzamento, $\in (0,1)$.
Poli e zeri sono definiti da:
\begin{displaymath}
    \left\{\textrm{poli di }G(s)\right\} = \left\{-\delta\omega_n \pm j\omega_n \sqrt{1-\delta^2}\right\} \hspace{10px}\left\{\textrm{modi di }G(s)\right\} = \left\{e^{-\delta\omega_nt}sen\left(\omega_n\sqrt{1-\delta^2}t+\phi_1\right)\right\}
\end{displaymath}
Determiniamo la risposta al gradino unitario, come sempre, con l'antitrasformata:
\begin{displaymath}
    y(t)=\mathcal{L}^{-1}\left[\frac{\omega_n^2}{s(s^2 + 2\delta\omega_n s+\omega_n^2)}\right] = 1-Ae^{-\delta\omega_nt} sen(\omega t + \phi)
\end{displaymath}
\begin{displaymath}
    \omega := \omega_n \sqrt{1-\delta^2}\hspace{10px}A:=\frac{1}{\sqrt{1-\delta^2}}\hspace{10px}\phi:=arccos(\delta)
\end{displaymath}
Notiamo che per $\delta=1, A$ tende ad infinito quindi bisogna ricalcolare l'antitrasformata. La massima sovraelongazione $S$ è invece pari a
\begin{displaymath}
    S = 100exp\left\{-\frac{\delta \pi}{\sqrt{1-\delta^2}}\right\}
\end{displaymath}
I tempi di asservimento e salita, invece:
\begin{displaymath}
    T_a \cong \frac{3}{\delta\omega_n}\hspace{10px}T_s \approx \frac{1,8}{\omega_n}
\end{displaymath}
Com'è evidente, la seconda è approssimata, frutto di interpolazione.
\subsection{Poli dominanti di un sistema generico}
Un sistema $\Sigma$ generico con funzione di trasferimento $G(s)=\frac{b(s)}{a(s)}$, con n poli e $m$ zeri, tutti i poli hanno parte reale negativa (i modi convergono a zero per $t\rightarrow+\infty$). Definiamo i \textbf{poli dominanti} come i poli (normalmente una coppia) non soggetti a quasi cancellazione polo-zero, più vicini all'asse immaginario. La risposta al gradino unitario dipende approssimativamente dai soli poli dominanti: se i poli dominanti sono complessi coniugati, i parametri della risposta $S, T_a, T_s$ sono determinabili approssimativamente dalle relazioni per i sistemi di ordine due. Bisogna però fare attenzione: spesso può essere un'approssimazione abbondante, e non sempre è possibile individuare un insieme significativo di poli dominanti. 
\subsection{Specifiche sulla risposta al gradino per un sistema di controllo}
Siamo ora in grado di poter definire delle specifiche sulla risposta al gradino grazie ai parametri definiti: imponiamo infatti le specifiche $S \le S_{max}$ e $T_a \le T_{a-max}$, ottenendo che i poli $-\delta\omega_n \pm j\omega_n \sqrt{1-\delta^2}$ devono appartenere ad un cono troncato.

\section{La stabilità dei sistemi dinamici}
\subsection{Stabilità alle perturbazioni}
Consideriamo un sistema dinamico $\Sigma$ nella solita forma $\sum_{i=0}^n a_i D^i y = \sum_{i=0}^m b_i D^i u$ e andiamo ad analizzarne i punti di equilibrio, ossia quei valori costanti di ingresso/uscita che si mantengono inalterati nel tempo. Andiamo quindi ad analizzare una coppia di valori $u_c, y_c$ devono rispettare la relazione $y_c = G(0)u_c$. Possiamo quindi mettere i punti a grafico, che evidentemente staranno su una retta con pendenza data dal guadagno statico $\frac{b_0}{a_0}$.
Introduciamo il concetto di stabilità. Per semplicità ci concentreremo solo sul punto di equilibrio che sta nell'origine. Ipotizziamo anche che $a(s)$ e $b(s)$ siano coprimi (non hanno radici in comune). Esaminiamo una perturbazione alla condizione di equilibrio, ad esempio introducendo un segnale di ingresso o modificando l'uscita nell'intervallo $[t_0,0)$. 
Distinguiamo tra tre tipologie di risposta a questa condizione: instabilità, stabilità semplice, stabilità asintotica. Formalizziamo la perturbazione come
\begin{displaymath}
    u(t) = 0 \textrm{ per }t<t_0, u(t) \neq 0 \textrm{ per }t\in[t_0, 0), u(t)=0 \textrm{ per }t\ge0
\end{displaymath}
\begin{displaymath}
    y(t) = 0 \textrm{ per }t<t_0, y(t) \neq 0 \textrm{ per }t\in [t_0,0), y(t)=y_{lib}(t) \textrm{ per }t\ge0
\end{displaymath}
Di conseguenza, l'uscita è in evoluzione libera per $t\ge0$.
Torniamo alla classificazione precedente:
\begin{itemize}
    \item $y_{lib}(t)$ è limitata su $[0,+\infty)$ punto di equilibrio \textbf{stabile}
    \item $y_{lib}(t)$ non è limitata su $[0,+\infty)$ punto di equilibrio \textbf{instabile}
    \item Se è stabile e convergente a $0$ per $t\rightarrow+\infty$ punto di equilibrio \textbf{asintoticamente stabile}
    \item È \textbf{semplicemente stabile} se è stabile ed esiste una perturbazione per la quale \begin{displaymath}
        lim_{t\rightarrow+\infty}y_{lib}(t)=y_\infty \neq 0 \vee \left\{\textrm{non esiste} lim_{t\rightarrow+\infty} y_{lib}(t)\right\}
    \end{displaymath} 
\end{itemize}
\begin{center}
    Per il sistema lineare $\Sigma$, il comportamento della risposta libera a seguito di perturbazioni su di un punto, rimane il medesimo per tutti gli altri punti. Possiamo quindi parlare di stabilità del sistema piuttosto che del singolo punto.
\end{center}
\subsection{Teorema sui poli e la stabilità}
La stabilità è strettamente legata ai poli del sistema. Consideriamo un sistema $\Sigma$ lineare per il quale i poli coincidono con le radici del polinomio caratteristico ($a(s)$ e $b(s)$ coprimi). Valgono le seguenti condizioni necessarie e sufficienti:
\begin{itemize}
    \item $\Sigma$ è \textbf{stabile} se e solo se tutti i poli hanno parte reale non positiva e gli eventuali poli puramente immaginari sono semplici
    \item $\Sigma$ è \textbf{asintoticamente stabile} se e solo se tutti i suoi poli hanno parte reale negativa
    \item $\Sigma$ è \textbf{semplicemente stabile} se e solo se tutti i poli hanno parte reale non positiva e quelli puramente immaginari (che devono esistere, al massimo è $s=0$) sono semplici 
    \item $\Sigma$ è \textbf{instabile} se e solo se esiste almeno un polo a parte reale positiva o un polo puramente immaginario con molteplicità maggiore di 1.
\end{itemize}
\subsection{Stabilità bounded-input bounded-output}
La cosiddetta \textbf{stabilità BIBO} è così definita:
\begin{center}
    $\Sigma$ è BIBO stabile se per ogni azione forzante limitata la corrispondente risposta forzata è limitata.
\end{center}
Formalmente, è BIBO stabile se per ogni azione forzante la cui norma infinito $||u(t)||_\infty$ sia $<+\infty$, la norma infinito della risposta forzata $||y(t)||_\infty$ generata sia $<+\infty$.
Grazie a un teorema, possiamo affermare che $\Sigma$ è BIBO stabile se e solo se 
\begin{displaymath}
    \int_0^{+\infty} |g(\tau)|d\tau < +\infty
\end{displaymath}
Un altro teorema utile è il seguente. Assumiamo $a(s)$ e $b(s)$ coprimi. Vale la seguente equivalenza:
\begin{center}
    Il sistema $\Sigma$ è BIBO stabile se e solo se $\Sigma$ è asintoticamente stabile. 
\end{center}
I due concetti vengono spesso utilizzati equivalentemente.
\end{document}

