\documentclass[11pt]{article}
\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[normalem]{ulem}
\newcommand{\numpy}{{\tt numpy}}    % tt font for numpy

\topmargin -.5in
\textheight 9in
\oddsidemargin -.25in
\evensidemargin -.25in
\textwidth 7in

\begin{document}

% ========== Edit your name here
\author{Simone Montali - monta.li}
\title{Fondamenti di Controlli Automatici}

\maketitle

\medskip
\section{Il controllo attivo di un processo}
Innanzitutto definiamo due termini fondamentali per la materia: un \textbf{processo} è l'evoluzione nel tempo di ciò che caratterizza un sistema. Con \textbf{controllo attivo} intendiamo una strategia di controllo che prevede un'azione di comando esercitata sul processo. 
Il controllo attivo risolve il problema di imporre una modalità di funzionamento desiderato ad un processo: l'obiettivo è che una variabile del processo coincida con una preassegnata. Parliamo di \textbf{regolazione} quando l'ingresso è costante, di \textbf{asservimento} quando l'ingresso è variabile. 
Un \textbf{sistema} è un complesso, normalmente composto da più elementi interconnessi, in cui si possono distinguere grandezze soggette a variare nel tempo (variabili). Un \textbf{segnale} è una funzione che rappresenta l'andamento delle variabili nel tempo. Distinguiamo queste ultime in indipendenti (ingressi) e dipendenti (uscite). Arriviamo così al concetto di \textbf{sistema orientato}. Un \textbf{modello matematico} è la descrizione di un sistema che permette di determinare i segnali delle uscite noti gli ingressi e le condizioni iniziali. Distinguiamo tra sistemi multivariabili (MIMO) e scalari (SISO). Un sistema è detto \textbf{statico} quando l'uscita al tempo $t$ dipende esclusivamente dall'ingresso al medesimo tempo $t$. Un \textbf{sistema dinamico}, invece, ha uscita dipendente dal segnale di ingresso sull'intervallo $(-\infty , t]$, e ha quindi memoria. Per questi ultimi sistemi introduciamo i concetti di sistema in quiete (\textit{equilibrio}) e sistema in condizioni asintotiche(\textit{stazionarie}). 
\subsection{Insieme dei behavior}
Definiamo ora l'\textbf{insieme dei behavior} $\mathcal{B}$ come l'insieme di tutte le possibili coppie causa-effetto associate ad un sistema.
\begin{displaymath}
    \mathcal{B}:={\left( u(t), y(t) \right) : y(t)}
\end{displaymath}
è l'uscita del sistema corrispondente all'ingresso $u(t)$, con $u(t)$ e $y(t)$ che tipicamente appartengono agli spazi funzionali delle funzioni continue o differenziabili a tratti. 
Un sistema è \textbf{lineare} se soddisfa la proprietà di sovrapposizione degli effetti. 
\begin{displaymath}
    \forall (u_1,y_1), (u_2, y_2) \in \mathcal{B}, \forall \alpha_1,\alpha_2 \in \mathcal{R} \rightarrow \alpha_1(u_1,y_1)+\alpha_2(u_2, y_2) := (\alpha_1 u_1+ \alpha_2 u_2, \alpha_1y_1 + \alpha_2 y_2) \in \mathcal{B}
\end{displaymath}
Con \textbf{stazionario} intendiamo un sistema invariante nel tempo, ossia:
\begin{displaymath}
    \left(u(t), y(t)\right) \in \mathcal{B} \rightarrow \left(u(t-T), y(t-T)\right) \in \mathcal{B}
\end{displaymath}
\subsection{Controllo ad azione diretta e retroazione}
Vi è, tra le tipologie di controllo, una distinzione importantissima: quella tra i controlli \textbf{ad azione diretta} e quelli \textbf{in retroazione}. 
Nel primo, l'azione di comando dipende da: obiettivo perseguito, informazioni sul modello del sistema controllato, ingressi agenti sul sistema controllato. Nel secondo, oltre ai suddetti, vi è l'intervento della \textbf{variabile controllata}. In altri termini, l'ingresso dipende anche dall'uscita. Introduciamo poi anche i controlli feedforward/feedback a due/tre gradi di libertà. 
È utile notare come in sistemi disturbati, in cui cioè abbiamo una perturbazione data dal sistema stesso, il controllo ad azione diretta non la smorza, mentre quello in retroazione riduce l'errore di svariati ordini di grandezza. Bisogna però portare attenzione ai \textbf{fenomeni di instabilità} che nascono all'aumentare del guadagno di anello. 
\section{Modellistica ed equazioni differenziali lineari}
\subsection{Cenni di modellistica}
La \textbf{modellistica} è la costruzione dei modelli matematici dei sistemi, a partire da leggi fondamentali o dati sperimentali.
\subsubsection{Circuiti elettrici}
Citiamo anzitutto alcuni esempi elettrici di leggi fondamentali:\\
\begin{center}
Resistenza: $v_R = Ri$\\
Induttanza: $v_L=L\frac{di}{dt} = LDi$\\
Capacità: $v_c = \frac{Q}{C} = \frac{1}{C} \int_{-\infty}^t i(\tau)d\tau \rightarrow Dv_c = \frac{i}{C}$\\
\end{center}

Un circuito RLC diventa quindi
\begin{displaymath}
    v_i=v_L+v_R+v_c\\
    v_i(t) = LDi(t) + Ri(t)+ \frac{1}{C} \int_{-\infty}^t i(\tau)d\tau
\end{displaymath}
Calcoliamo quindi l'equazione differenziale lineare a coefficienti costanti:
\begin{displaymath}
    LD^2i+RDi+\frac{1}{C}i = Dv_i
\end{displaymath}
Costruiamo il modello matematico orientato da $v_i$ a $v_u$.
\begin{displaymath}
    LCD^2 v_u + RCDv_u + v_u = v_i
\end{displaymath}
\subsubsection{Sistemi meccanici}
Citiamo ora tre sistemi meccanici e le rispettive leggi del moto.
\begin{center}
    Massa: $MD^2x(t) = f_1(t) - f_2(t)$\\
    Molla: $f(t)=K(x_1(t)-x_2(t))$\\
    Ammortizzatore: $f(t) = B(v_1(t)-v_2(t)) \hspace{20px} f(t) = BD(x_1(t)-x_2(t))$
\end{center}
Introduciamo un sistema meccanico vibrante composto dai tre elementi, che avrà quindi equazione da f a x:
\begin{displaymath}
    mD^2 x(t) + bDx(t) + kx(t) = f(t)
\end{displaymath}
Otteniamo l'equazione differenziale
\begin{displaymath}
    mD^2y+bDy+ky = Df
\end{displaymath}
\subsubsection{OP-AMP}
Citiamo anche i circuiti elettrici con OP-AMP, deducendo 
\begin{displaymath}
    R_1CDy + y = -R_2CDu-u
\end{displaymath}
\subsection{Equazioni differenziali lineari}
Le equazioni differenziali lineari a coefficienti costanti possono rappresentare quindi sistemi scalari, generalizzando così:
\begin{displaymath}
    \sum_{i=0}^n a_i D^i y = \sum_{i=0}^m b_i D^i u
\end{displaymath}
Otteniamo così un modello matematico formale del sistema dinamico (orientato) $\Sigma, y =$ variabile d'uscita, $u=$ variabile d'ingresso, $a_n \neq 0, b_m \neq 0$. $n$ è l'ordine dell'eq. differenziale per estensione ordine di $\Sigma$, $n\ge m$; $\rho := n-m$ ordine relativo o grado relativo di $\Sigma$.
Ricollegandoci al concetto di \textbf{insieme dei behaviors} $\mathcal{B}$ di $\Sigma$, la coppia di segnali $\mathcal{B} := \{\left(u(t), y(t)\right)$ soddisfa l'equazione differenziale se $u(t)$ e $y(t)$ sono derivabili tante volte quanto necessario. 
\subsubsection{Proprietà del sistema}
Citiamo allora alcune proprietà del sistema. Per le dimostrazioni riferirsi alle slide.
\begin{itemize}
    \item Il sistema è lineare.
    \item Il sistema è stazionario.
\end{itemize}
\subsection{Determinazione dei segnali di uscita}
Una volta introdotto il sistema, sorge spontaneo un dubbio fondamentale:
\begin{center}
    \textbf{Noto il segnale di ingresso $u(t)|_{[0, +\infty]}$ e le condizioni iniziali $y(0), Dy(0),...,D^{n-1}y(0)$ determinare il segnale di uscita $y(t)|_{[0, +\infty]}$}
\end{center}
Se avessimo un'equazione omogenea, la soluzione sarebbe immediata. Ma spesso non è così, e ci serve un metodo generale per poter trattare le diverse casistiche. 
La classe dei segnali che utilizzeremo è $C_p^\infty$, insieme delle funzioni infinitamente derivabili a tratti. 
\begin{center}
    \textit{Una funzione appartiene a $C_p^\infty$ se esiste un insieme sparso $\mathcal{S}$ per il quale $f \in C^\infty (\mathbb{R}/S, \mathbb{R})$ e per ogni $n \in \mathbb{N}$ e per ogni $t \in \mathcal{S}$ i limiti $f^{(n)}(t^-)$ e $f^{(n)}(t^+)$ esistono e sono finiti. Quando $f$ è definita in $t \in \mathcal{S}$, convenzionalmente $f(t) := f(t^+)$. In particolare $C^{-1} := C_p^\infty (\mathbb{R})$ definisce l'insieme delle funzioni di classe $C^\infty$ a tratti definite su tutto $\mathbb{R}$}
\end{center}
\subsubsection{Proprietà di $C_p^\infty$}
In generale, sappiamo che $C^k \not\subset C^\infty_p$ e che $C_p^{k,\infty} := C^k \cap C^\infty_p$.
\subsubsection{Grado di continuità di una funzione o segnale}
Definiamo il grado di continuità di una funzione o segnale:
\begin{center}
    \textit{Se $f \in C_p^{k,\infty}, k $ è il grado di continuità di $f$.}
\end{center}
\begin{displaymath}
    \overline{C_p^{k,\infty}} := \left\{ f:\mathbb{R} \rightarrow \mathbb{R}:f \in C_p^{k, \infty}  \wedge f \not\in C_p^{k+1,\infty}\right\}
\end{displaymath}
Se $f \in \overline{C_p^{k,\infty}}$ allora $k$ è il grado massimo di continuità di $f$.
\subsubsection{Trasformate di Laplace}
Il metodo generale proposto per "integrare" l'equazione differenziale di $\Sigma$ si basa sulla \textbf{trasformata di Laplace}, che permette di trasformare un'equazione differenziale in un'equazione algebrica.
\section{Cenni di analisi complessa}
\subsection{Limite di una funzione complessa}
Consideriamo una funzione complessa di variabile complessa $f: \mathbb{C} \rightarrow \mathbb{C} s \rightarrow f(s)$. Se $s = \sigma + j \omega$, allora $f(s) = u(\sigma, \omega)+ jv(\sigma, \omega)$. Definiamo il limite $lim_{s\rightarrow s_0} f(s) = \lambda$ con la classica definizione da Analisi 1:
\begin{center}
    $\forall \epsilon >0, \exists \rho >0$ tale che se $s$ soddisfa $0<|s-s_0|<\rho \rightarrow |f(s) - \lambda| < \epsilon$
\end{center}
\subsubsection{Altre proprietà derivate}
Data questa definizione, possiamo definire altre proprietà, come la \textbf{continuità}: $f$ è continua in $s=s_0$ se $lim_{s\rightarrow s_0} f(s) = f(s_0)$. Da qui, $f(s)$ è continua in $s_0 = \sigma_0 + j\omega_0$ sse le funzioni reali $u(\sigma, \omega), v(\sigma, \omega)$ sono continue in $(\sigma_0, \omega_0)$. Definiamo poi la \textbf{derivabilità}: $f(s)$ è derivabile in $s=s_0$ se esiste il limite 
\begin{displaymath}
    lim_{\Delta s\rightarrow 0} \frac{f(s_0 + \Delta s) - f(s_0)}{\Delta s}
\end{displaymath}
Le regole base di derivabilità dell'analisi rimangono valide. Definiamo l'\textbf{analiticità}, ossia, $f(s)$ è analitica/olomorfa in $s=s_0$ se $f(s)$ è derivabile su di un intorno aperto contenente $s_0$. 
Infine, definiamo le \textbf{condizioni di Cauchy-Riemann}: $u(\sigma, \omega), v(\sigma, \omega)$ soddisfano le condizioni di Cauchy-Riemann se 
\begin{displaymath}
    \begin{cases} 
        \frac{\partial u}{\partial \sigma} = \frac{\partial v}{\partial \omega} \\ \frac{\partial u}{\partial \omega} = - \frac{\partial v}{\partial \sigma}
    \end{cases}
\end{displaymath}
\paragraph{Teorema}
Sia $f(s) = u(s) + jv(s)$:
\begin{enumerate}
    \item Se esiste $f^{(1)} (s_0)$ con $s_0 = \sigma_0 + j\omega_0$ allora esistono le derivate parziali di $u(\sigma, \omega), v(\sigma, \omega)$ in $(\sigma_0, \omega_0)$ e soddisfano le equazioni di Cauchy-Riemann
    \item Se $u(\sigma, \omega), v(\sigma, \omega)$ e le loro derivate parziali sono continue in $(\sigma_0, \omega_0)$ e soddisfano le condizioni di Cauchy-Riemann, allora esiste $f^{(1)} (s_0)$ con $s_0 = \sigma_0 + j\omega_0$
\end{enumerate}
\paragraph{Corollario}
Sia $f(s) = u(s) + jv(s)$ con $u(\sigma, \omega), v(\sigma, \omega)$ e le loro derivate parziali continue su di un dominio aperto $U \subseteq C$. Allora $f(s)$ è analitica su $U$ se e solo se $u(\sigma, \omega), v(\sigma, \omega)$ soddisfano, su U, le condizioni di Cauchy-Riemann. 
\paragraph{Teorema} 
Sia $f(s)$ analitica su di una regione aperta $U \subseteq C$. Allora la derivata $Df(s)$ è anch'essa una funzione analitica su $U$.
\paragraph{Corollario}
Se $f(s)$ è analitica sulla regione aperta $U$, allora $f(s)$ è ivi derivabile indefinitivamente.
\subsection{Integrali di linea nel piano complesso}
Definiamo innanzitutto l'\textbf{integrale}: data una funzione $f(s)$ ed una curva $\Gamma$ su $\mathbb{C}$ percorsa da $s_a$ a $s_b$, definiamo $\int_\Gamma f(s) ds \triangleq lim_{n\rightarrow \infty} \sum_{i=1}^n f(s_i)(s_i- s_{i-1})$ dove $s_0,...,s_n$ è una discretizzazione uniforme della curva $\Gamma$. 
\subsubsection{Calcolo dell'integrale di linea}
Sia $\Gamma$ una curva parametrica di classe $C^1$.
\begin{displaymath}
    \int_\Gamma f(s) ds = \int_a^b f\left(\Gamma(u) \right) \frac{d\Gamma}{du} du
\end{displaymath}

Definiamo una \textbf{curva chiusa semplice} come una curva continua tale che $\Gamma(a)=\Gamma(b)$ e $\Gamma(u_1) \neq \Gamma(u_2) \forall u_1 \neq u_2 \in (a,b)$
Il \textbf{teorema di Jordan} afferma che se $\Gamma$ è una curva chiusa semplice in $\mathbb{C}$ questa suddivide il piano complesso in due regioni distinte, una esterna e una interna. 
Definiamo un \textbf{insieme connesso} se per ogni coppia di punti appartenenti all'insieme esiste una curva continua $\Gamma$ che li congiunge tutta contenuta in R. È invece detto \textbf{semplicemente connesso} se è connesso e per ogni curva chiusa semplice $\Gamma$ appartenente all'insieme la regione interna di $\Gamma$ è tutta contenuta in R.
\paragraph{Teorema dell'integrale di Cauchy}
Sia $f(s)$ una funzione analitica su di una regione aperta e semplicemente connessa $U$ e $\Gamma$ una curva semplice ivi contenuta. Allora $\oint_\Gamma f(s) ds = 0$. 
\paragraph{Corollario}
Sia $f(s)$ una funzione analitica su di una regione aperta e semplicemente connessa $U$ e $\Gamma$ una curva ivi contenuta che congiunge $s_a$ ad $s_b$. Allora l'integrale di linea $\int_\Gamma f(s)ds$ non dipende dal percorso $\Gamma$ ma solo da $s_a, s_b$ e $f(s)$:
\begin{displaymath}
    \int_\Gamma f(s)ds = \int_{s_a}^{s_b} f(s)ds
\end{displaymath}
\paragraph{Teorema - Sviluppo in serie di Taylor}
Sia $f(s)$ una funzione analitica su di un cerchio $B(s_0, r_0)$ centrato su $s_0$ e con raggio $r_0$. Allora $\forall s \in B(s_0, r_0)$ 
\begin{displaymath}
    f(s) = \sum_{i=0}^\infty c_i (s-s_0)^i
\end{displaymath}
dove 
\begin{displaymath}
    c_i = \frac{f^{(i) (s_0)}}{i!} = \frac{1}{2\pi j}\oint \frac{f(s)}{(s-s_0)^{i+1}}ds
\end{displaymath}
Come corollario, otteniamo la \textbf{formula integrale di Cauchy}
\begin{displaymath}
    f(s_0) = \frac{1}{2\pi j} \oint_\Gamma \frac{f(s)}{s-s_0} ds
\end{displaymath}
\paragraph{Teorema - Sviluppo in serie di Laurent}
Sia $f(s)$ una funzione analitica sul cerchio $B(s_0, r_0)$ ad eccezione del suo centro $s_0$. Allora $\forall s \in B(s_0, r_0)- \{s_0\}$
\begin{displaymath}
    f(s) = \sum_{i=-\infty}^{+\infty} c_i(s-s_0)^i
\end{displaymath}
dove 
\begin{displaymath}
    c_i = \frac{f^{(i) (s_0)}}{i!} = \frac{1}{2\pi j}\oint \frac{f(s)}{(s-s_0)^{i+1}}ds
\end{displaymath}
\subsection{Classificazione del punto isolato $s_0$}
Se $c_i =0 \forall i \in \mathbb{Z}^-$ definendo $f(s_0) = c_0$ risulta $f(s)$ analitica in $s=s_0$. Se $c_i \neq 0$ per qualche $i \in \mathbb{Z}^-$, $s_0$ è una singolarità di $f(s)$, detta \textbf{singolarità polo} quando i $c_i \neq 0$ sono in numero finito, con $-n = min\{i\in \mathbb{Z}^-: c_i \neq 0\}$ $s_0$ è polo di ordine $n$. Invece abbiamo una \textbf{singolarità essenziale} quando i $c_i \neq 0$ con $i \in \mathbb{Z}^-$ sono infiniti. Se abbiamo una $f(s)$ analitica in $B(s_0, r_0) - \{s_0\}$, $s_0$ è una singolarità di $f(s)$ se e solo se $f(s)$ assume valori illimitati in un intorno di $s_0$. 
Il \textbf{Teorema di Picard} afferma che se abbiamo $s_0$ singolarità essenziale di $f(s)$, in ogni intorno di $s_0$ la funzione $f(s)$ assume ogni valore complesso infinite volte con l'eventuale eccezione di un solo particolare valore. 
\subsubsection{Residui}
Data una singolarità $s_0$, definiamo il \textbf{residuo} come il coefficiente $c_{-1}$ dello sviluppo in serie di Laurent.
\paragraph{Teorema dei residui di Cauchy}
Sia $\Gamma$ una curva chiusa semplice e $f(s)$ una funzione analitica su $\Gamma$ e nella sua regione interna ad eccezione dei punti singolari $s_1,...,s_n$ in essa contenuti, allora 
\begin{displaymath}
    \oint_\Gamma f(s) ds = 2\pi j \sum_{i=1}^n Res\{f, s_i\}
\end{displaymath}
\subsubsection{Poli e zeri}
Sia $s_0$ una singolarità polo di $f(s)$. Allora $s_0$ è polo di ordine $n$ sse esiste $g(s)$ analitica in $s_0$ con $g(s_0) \neq 0$ tale che 
\begin{displaymath}
    f(s) = \frac{g(s)}{(s-s_0)^n}
\end{displaymath}
Sia $f(s)$ analitica in $z$. $z$ è detto \textbf{zero} di $f$ se $f(z)=0$. Considerato lo sviluppo di Taylor $f(s)= c_1(s-z)+\dots$ ed $n:=min\{i \in \mathbb{N}: c_i \neq 0\}$, $z$ è detto zero di ordine $n$ di $f(s)$. È detto tale se e solo se esiste $g(s)$ analitica in $z$ con $g(z) \neq 0$ tale che $f(s) = (s-z)^n g(s)$. Ricaviamo un'ultima proprietà: se $f: \mathbb{C} \rightarrow \mathbb{C}$ ha una singolarità polare in $p$ di ordine $n$ allora 
\begin{displaymath}
    Res\{f,p\} = \frac{1}{(n-1)!} D^{n-1} \left(f(s)(s-p)^n\right)|_{s=p}
\end{displaymath}
\subsection{Continuazione analitica}
Data una funzione $f(s)$ definita da uno sviluppo in serie di Taylor su di un cerchio $B_0(s_0, r_0)$ è possibile estendere/continuare la definizione di $f(s)$ all'esterno di $B_0$ mediante lo sviluppo in serie di Taylor di altri punti di $B_0$. Il procedimento è ricorsivo. Possono anche emergere funzioni a più valori!
\section{La trasformata di Laplace}
La \textbf{trasformata di Laplace} è un operatore funzionale che converte un'equazione differenziale in un'equazione algebrica, permettendo di risolvere anche equazioni differenziali lineari con condizioni iniziali arbitrarie.
Permette inoltre di analizzare i fenomeni transitori ed asintotici di una grande varietà di sistemi. 
Si applica ad una funzione $f$ di variabile reale con codominio $\mathbb{R}$ o $\mathbb{C}$. Assumiamo ora $f \in \mathbb{C}_p^\infty (\mathbb{R})$, sappiamo che $\exists \sigma \in \mathbb{R}$ per il quale $\int_0^{+\infty} |f(t)| e^{-\sigma t} dt < + \infty$. Se vale quest'ultima condizione, allora $\forall \sigma_1 > \sigma : \int_0^{+\infty} |f(t)| e^{-\sigma_1 t} dt < + \infty$. Definiamo l'\textbf{ascissa di convergenza} di $f(t)$ come $\sigma_c := inf \left\{\sigma \in \mathbb{R} : \int_0^{+\infty}|f(t)| e^{- \sigma t} dt\right\}$ Spesso assumeremo $f(t) = 0$ per $t<0$. 
Volendo ora dare una definizione rigorosa della trasformata, 
\begin{center}
    La trasformata di Laplace di un segnale (funzione) $f(t)$ è la funzione $F(s) = \mathcal{L}[f(t)]$ definita da
    \begin{displaymath}
        F(s) = \int_0^{+\infty} f(t) e^{-st} dt
    \end{displaymath}
    per i valori $s\in \mathbb{C}$ per i quali l'integrale converge.
\end{center}
Notiamo alcune cose:
\begin{itemize}
    \item $F$ è una funzione complessa di variabile complessa, $\mathcal{L}[\dot]$ indica l'operatore di Laplace.
    \item La notazione usuale prevede che le lettere minuscole denotino segnali e funzioni, le corrispondenti maiuscole le loro trasformate.
\end{itemize}
\subsection{Proprietà della trasformata}
\subsubsection{Analitica}
La trasformata $F(s)$ è una funzione analitica sul semipiano $\left\{s \in \mathbb{C}: Re s > \sigma_c\right\}$
\subsubsection{Coniugato}
Denotando il coniugato con $\overline{ }$, $\overline{F(s)} = F(\overline{s})$
\subsubsection{Linearità}
La trasformata di Laplace è un operatore lineare: per ogni segnale $f_1(t)$ e $f_2(t)$ e per ogni scalare $c_1$ e $c_2$:
\begin{displaymath}
    \mathcal{L}[c_1 f_1 (t) + c_2f_2(t)] = c_1 \mathcal{L}[f_1(t)] + c_2 \mathcal{L}[f_2(t)]
\end{displaymath}
\subsubsection{Iniettività}
La trasformata di Laplace è \textbf{iniettiva}:
\begin{displaymath}
    \mathcal{L}[f(t)] = \mathcal{L}[g(t)] \rightarrow f(t) = g(t) \textrm{ su }[0, +\infty )
\end{displaymath}
È quindi ben definita la trasformata inversa.
\subsection{La trasformata inversa di Laplace}
Sia $F(s) = \mathcal{L}[f(t)]$ allora, per ogni $\sigma_0 > \sigma_c$
\begin{displaymath}
    \mathcal{L}^{-1} \rightarrow f(t) = \frac{1}{2\pi j} \int_{\sigma_0-j\infty}^{\sigma_0+j\infty} F(s) e^{st} ds
\end{displaymath}
\subsection{Trasformate notevoli}
\subsubsection{Trasformata della derivata}
Sia $f \in C^1 (\mathbb{R}_{>0})$ segue
\begin{displaymath}
    \mathcal{L}[Df(t)] = sF(s) - f(0+)
\end{displaymath}
Generalizzando per gli ordini superiori, otteniamo
\begin{displaymath}
    \mathcal{L}[D^i f] = s^i F(s) - \sum_{j=0}^{i-1} s^j D^{i-1-j} f_+
\end{displaymath}
\subsubsection{Trasformata dell'integrale}
\begin{displaymath}
    \mathcal{L}\left[\int_0^t f(v) dv\right] = \frac{1}{s} F(s)
\end{displaymath}
\subsection{Teoremi e gotchas}
\subsubsection{Teorema del valore finale}
Sia $f\in C^1 (\mathbb{R}_+)$ con $f$ e $Df$ aventi ascisse di convergenza non positive. Se esiste il limite $lim_{t\rightarrow+\infty} f(t)$ vale
\begin{displaymath}
    lim_{t\rightarrow+\infty} f(t) = lim_{s\rightarrow0} sF(s)
\end{displaymath}
\subsubsection{Teorema del valore iniziale}
Sia $f\in C^1 (\mathbb{R}_+)$. Se esiste il limite $lim_{s\rightarrow+\infty} sF(s)$ vale
\begin{displaymath}
    f(0+)=lim_{s\rightarrow+\infty} sF(s)
\end{displaymath}
\subsubsection{Traslazione nel tempo}
Per ogni $t_0 \ge 0$ vale 
\begin{displaymath}
    \mathcal{L}[f(t-t_0)\cdot 1(t-t_0)]= e^{-t_0s}F(s)
\end{displaymath}
\subsubsection{Traslazione nella variabile complessa $s$}
Per ogni $a \in \mathbb{R}(\mathbb{C})$ vale 
\begin{displaymath}
    \mathcal{L}[e^{\alpha t} f(t)] = F(s-a)
\end{displaymath}
\subsubsection{Teorema di convoluzione}
Si abbia $f(t) = g(t)=0$ per $t<0$. La convoluzione dei segnali $f$ e $g$, spesso indicata come $f*g$, è il segnale 
\begin{displaymath}
    \int_0^t f(v)g(t-v)dv
\end{displaymath}
rappresentabile anche come $f*g=g*f$
\begin{displaymath}
    \int_0^t g(v) f(t-v) dv
\end{displaymath}
La trasformata della convoluzione è 
\begin{displaymath}
    \mathcal{L}\left[    \int_0^t f(v)g(t-v)dv\right] = F(s)G(s)
\end{displaymath}
\subsection{Antitrasformazione di funzioni razionali}
Per antitrasformare le funzioni razionali, sfruttiamo il \textbf{metodo dei fratti semplici}, ossia scomponiamo il denominatore in poli semplici e poi cerchiamo i $k_i$:
\begin{displaymath}
    F(s) = \frac{k_1}{(s-p_1)}+\frac{k_2}{(s-p_2)}+...+\frac{k_n}{(s-p_n)}
\end{displaymath}
Con i $k_i$ rappresentanti il residuo di $F(s)$ in $p_i$, e pari a
\begin{displaymath}
    k_i= (s-p_i)F(s)|_{s=p_i}
\end{displaymath}
Ottenendo
\begin{displaymath}
    f(t) = \sum_{i=1}^n k_i e^{p_it}
\end{displaymath}
\subsection{Trasformate notevoli}
Citiamo infine altre due trasformate notevoli:
\begin{displaymath}
    \mathcal{L}[t^n] = \frac{n!}{s^{n+1}} \hspace{10px} \mathcal{L}[e^{\alpha t}] = \frac{1}{s-a}
\end{displaymath}
\section{Le funzioni impulsive e l'insieme dei behaviors}
Consideriamo anzitutto un sistema dinamico $\Sigma$ descritto da $Dy(t) + 2y(t) = 2Du(t)+2u(t)$ ed assumiamo che per i tempi negativi sia $y(t) = e^{-2t}$ e $u(t)=0$ con $t<0$.
Questa coppia di funzioni soddisfa l'eq. differenziale 
\begin{displaymath}
    Dy(t) = -2e^{-2t} \rightarrow (-2e^{-2t}) + 2(e^{-2t}) = 0 \forall t<0
\end{displaymath}
Quindi:
\begin{displaymath}
    \left(0, e^{-2t}\right)|_{(-\infty, 0)} \in \mathcal{B}
\end{displaymath}
Introduciamo ora nel sistema una azione forzante $u(t) = 1$ per $t \ge 0$. Quindi $u(t) = 1(t) \forall t \in \mathbb{R}$. Vogliamo determinare $y(t)$ per $t \ge 0$. Non possiamo però definire l'insieme dei behaviors eseguendo la trasformata di Laplace sull'equazione differenziale: otterremmo una soluzione valida per qualsiasi valore del parametro $y_+$, che sarebbe assurdo. L'insieme dei behaviors \textbf{errato} che si genera sarebbe così fatto:
\begin{displaymath}
    \mathcal{B}= \left\{\left(u(t), y(t)\right) \in C^\infty_p (\mathbb{R})^2 : Dy+ 2y = 2Du +2u \forall t \in \mathbb{R}-\left\{t_1,t_2,...\right\}\right\}
\end{displaymath}
Osserviamo però, che dato $C^{1, \infty}_p = C^1 \cap C_p^\infty$: 
\begin{displaymath}
    \left\{\left(u(t), y(t)\right) \in (C_p^{1,\infty})^2 : Dy + 2y = 2Du + 2u \forall t \in \mathbb{R}\right\} \subset \mathcal{B}
\end{displaymath}
Per risolvere l'impasse, definiamo l'azione forzante come 
\begin{displaymath}
    u(t) :=
    \begin{cases}
        0 \textrm{ per }t<0\\
        3\frac{t^2}{\tau^2}- 2\frac{t^3}{\tau^3} \textrm{ per }t \in [0, \tau)\\
        1 \textrm{ per } t \ge \tau
    \end{cases}
    \rightarrow u(t) \in C_p^{1,\infty} \forall \tau > 0
\end{displaymath}
Assumendo $y(t) \in C_p^\infty$ segue $y(0-) = y(0+) = 1$. Possiamo quindi determinare $y(t)$ con le condizioni iniziali al tempo $0+$: $u(0+)=0$ e $y(0+)=1$.
Portando $\tau \rightarrow 0+$ otteniamo la soluzione desiderata. Ma se la volessimo senza dover applicare tutte le volte questo metodo di smoothing?
Osserviamo che quando $\tau \rightarrow 0+$, $Du(t)$ in un intorno dell'origine diverge all'infinito. $Du(t) = 6\frac{t}{\tau^2} - 6\frac{t^2}{\tau^3}$ per $t \in [0, \tau] \rightarrow max_{t \in [0, \tau]} Du(t) = Du(t)|_{t=\frac{\tau}{2}}=\frac{3}{2\tau}$.
Insomma, $Du(t)$ converge ad una funzione impulsiva (distribuzione) detta \textbf{delta di Dirac $\delta(t)$}.
\subsection{Cenni di teoria delle funzioni impulsive}
La funzione impulsiva più semplice è il gradino unitario $1(t)$:
\begin{displaymath}
    1(t) := \begin{cases}
        0 \textrm{ per }t<0\\
        1 \textrm{ per }t\ge0
    \end{cases}
\end{displaymath}
Introduciamo $f(t<\tau) \in C_p^{0,\infty}$:
\begin{displaymath}
    f(t:\tau) :=
    \begin{cases}
        0 \textrm{ per } t<0\\
        \frac{1}{\tau} t \textrm{ per }0\le \le \tau\\
        1 \textrm{ per }t>\tau
    \end{cases}
\end{displaymath}
$lim_{\tau \rightarrow 0+} f(t:\tau) = 1(t)$.
La derivata di questa funzione sarà ovviamente pari a 0 per $t<0$ e $t\ge\tau$:
\begin{displaymath}
    Df(t;\tau) = 
    \begin{cases}
        0 \textrm{ per } t<0\\
        \frac{1}{\tau} \textrm{ per } 0\le t \le \tau\\
        0 \textrm{ per }t\ge\tau
    \end{cases}
\end{displaymath}
Notiamo altresì che $lim_{\tau\rightarrow 0+} Df(t;\tau)$ è proprio la delta di Dirac!
$\delta(t)$ è una distribuzione, o, più informalmente, una funzione impulsiva. È la \textbf{derivata generalizzata} del gradino unitario $\delta(t) := D^*1(t)$. $D^*$ è proprio l'operatore della derivata generalizzata: è un operatore lineare come $D$. Più precisamente, $D^*$ è la derivata in senso distribuzionale. Sappiamo inoltre che, assumendo $t_a < T < t_b$ 
\begin{displaymath}
    \int_{t_a}^{t_b} \delta(t-T)dt = 1 \hspace{10px} \int_{t_a}^{t_b} f(t)\delta(t-T)dt = f(T) 
\end{displaymath}
Introduciamo le derivate generalizzate di $\delta(t)$:
\begin{displaymath}
    D^{*i}\delta(t) \textrm{è la derivata generalizzata di ordine i della delta } =: \delta^{(i)}(t)
\end{displaymath}
Possiamo costruire $\delta^{(1)}(t)$ mediante limite di una funzione continua a tratti:
\begin{displaymath}
    1(t) = lim_{\tau\rightarrow0+}f(t;\tau) \hspace{10px} \delta(t):= D^* 1(t) = lim_{\tau\rightarrow0+} Df(t;\tau)
\end{displaymath}
\begin{displaymath}
    \delta^{(1)} (t) := D^* \delta(t) = lim_{\tau\rightarrow0+}D^2 f(t;\tau)
\end{displaymath}

Questo metodo si può estendere per mostrare il significato di $\delta^{(i)} (t), i>1$.
\subsection{Derivate generalizzate di una funzione discontinua}
Ipotizziamo $f \in C_p^\infty(\mathbb{R})$ e sia $t=0$ l'unico istante di discontinuità:
\begin{displaymath}
    g(t) := \begin{cases}
        f(t) \textrm{ per } t<0\\
        f(t)-(f_+ - f_-) \textrm{ per }t\ge0
    \end{cases}
    g(t) \in C_p^{0, \infty}
\end{displaymath}
Ottenendo
\begin{displaymath}
    g(t) = f(t) - (f_+ - f_-)1(t)
\end{displaymath}
ovvero, una funzione discontinua è pari a una funzione continua $+$ una funzione a gradino.
Derivando in senso usuale otteniamo $Df(t) = Dg(t) \forall t \neq 0$. Assumiamo ora che la derivata generalizzata di una funzione continua sia $D^* g(t) := Dg(t^+)$. Applicando l'operatore $D^*$ otteniamo
\begin{displaymath}
    D^* f(t) = Df(t^+) + (f_+ - f_-)\delta(t)
\end{displaymath}
Ossia, derivata gen. di ordine 1 $=$ funzione discontinua $+$ funzione impulsiva (di ordine 0). La funzione discontinua $Df(t^+)$ può essere scomposta nella somma di una funzione continua più una funzione a gradino:
\begin{center}
    derivata gen. di ordine 1 $=$ f. continua $+$ f. a gradino $+$ f. impulsiva di ordine 0. 
\end{center}
Applicando la derivata generalizzata alla relazione che esprime $D^*f(t)$, otteniamo
\begin{displaymath}
    D^{*2} f(t) = Dg_1(t^+) + (Df_+ - Df_-)\delta(t) + (f_+ - f_-)\delta^{(1)}(t)
\end{displaymath}
Iterando il tutto per generalizzare, otterremo 
\begin{displaymath}
    D^{*n} f(t) = D^n f(t^+) + (D^{n-1} f_+ - D^{n-1} f_-) \delta(t)+...+(f_+ - f_-)\delta^{(n-1)}(t)
\end{displaymath}
Che, con $t<0$ o $t>0$ è $D^{*n} f(t) = D^n f(t)$, mentre con $t=0$ è $D^{*n} f(0) = (D^{n-1} f_+ - D^{n-1} f_-) \delta(0) + ... + (f_+-f_-)\delta^{(n-1)}(0)$.
Più in generale: $f \in C_p^\infty (\mathbb{R})$ con $t_1,t_2,...$ istanti di possibile discontinuita:
\begin{displaymath}
D^{*n} f(t) = D^n f(t^+)+\end{displaymath}\begin{displaymath}
\left(D^{n-1}(t_1^+) - D^{n-1}(t_1^-)\right)\delta(t-t_1)+...+\left(f(t_1^+)-f(t_1^-)\right)\delta^{(n-1)}(t-t_1)+\end{displaymath}\begin{displaymath}
\left(D^{n-1}(t_2^+) - D^{n-1}(t_2^-)\right)\delta(t-t_2)+...+\left(f(t_2^+)-f(t_2^-)\right)\delta^{(n-1)}(t-t_2)+\dots
\end{displaymath}
\subsection{Principio di identità delle funzioni impulsive}
Le funzioni impulsive 
\begin{displaymath}
    c_{-1} + c_0 \delta(0) + c_1 \delta^{(1)}(0)+\dots+c_k\delta^{(k)}(0)
\end{displaymath}
e
\begin{displaymath}
    d_{-1} + d_0\delta(0)+d_1\delta^{(1)}(0)+\dots+d_k\delta^{(k)}(0)
\end{displaymath}
sono uguali fra loro sse $c_0=d_0,\dots,c_k=d_k$.
Ritornando all'esempio iniziale, quindi, l'eq. differenziale di $\Sigma$ interpretata in senso distribuzionale
\begin{displaymath}
    D^* y(t) + 2y(t) = 2D^* u(t) + 2u(t)
\end{displaymath}
deve essere soddisfatta per ogni $t \in \mathbb{R}$ compresi gli istanti di discontinuità.
\subsection{Insieme dei behaviors}
Dato un insieme dinamico $\Sigma$ descritto dall'eq. differenziale 
\begin{displaymath}
    \sum_{i=0}^n a_i D^i y = \sum_{i=0}^m b_i D^i u
\end{displaymath}
si definisce insieme dei behaviors di $\Sigma$
\begin{displaymath}
    \mathcal{B}:= \left\{(u,y)\in C_p^\infty (\mathbb{R})^2: \sum_{i=0}^n a_i D^{*i} y = \sum_{i=0}^m b_i D^{*i}u\right\}
\end{displaymath}
L'equazione differenziale è soddisfatta in senso distribuzionale per ogni $t \in \mathbb{R}$. Se abbiamo $t=0$ istante di discontinuità emergono le condizioni al tempo $0-$ e $0+$. Le relazioni fra i valori al tempo $0+$ ($y_-, Dy_-,\dots,D^{n-1}y_-; u_-\dots$) e quelli al tempo $0+$ ($y_+, Dy_+,\dots,D^{n+1}y_+; u_+\dots$) sono determinabili eguagliando le espressioni impulsive dell'eq. differenziale al tempo $t=0$.
\subsubsection{Proprietà}
Sia $\left(u(t),y(t)\right) \in \mathcal{B}$ con $u(t)$ funzione discontinua. Se $\rho=0$ allora anche l'uscita $y(t)$ è una funzione discontinua. Se $\rho\ge1$ allora $y(t) \in \overline{C_p^{\rho-1,\infty}}$.\\
Otteniamo anche una proprietà che definisce la relazione tra i gradi di continuità dell'ingresso e dell'uscita: sia $\left(u(t),y(t)\right) \in \mathcal{B}$ e $l \in \mathbb{N}$. Allora
\begin{displaymath}
    u(t)\in C_p^{l,\infty} \Leftrightarrow y(t)\in C_p^{\rho+l,\infty}, \hspace{10px}u(t)\in \overline{C_p^{l,\infty} }\Leftrightarrow y(t)\in \overline{C_p^{\rho+l,\infty}}
\end{displaymath}
\section{La funzione di trasferimento}
Definiamo anzitutto lo spazio delle sequenze impulsive $\mathcal{I}^*$:
\begin{displaymath}
    \mathcal{I}^* \triangleq \left\{d:\mathbb{R}\rightarrow\mathbb{R}^*:d(t) = \sum_{i=1}^{+\infty}\sum_{j=0}^{r_i} c_{ij}\delta^{(j)}(t-t_i), c_{ij} \in \mathbb{R}\right\}
\end{displaymath}
Estensione distribuzionale delle funzioni derivabili a tratti: $C_p^\infty (\mathbb{R})^* \triangleq C_p^\infty (\mathbb{R}) + \mathcal{I}^*$.
\subsection{La trasformata della derivata generalizzata}
Tenendo conto del solo istante di discontinuità in $t=0$, otteniamo, data $f \in C_p^{\infty} (\mathbb{R})(C_p^\infty(\mathbb{R})^*)$, segue
\begin{displaymath}
    \mathcal{L}[D^*f(t)] = sF(s) - f(0-)
\end{displaymath}
Per ottenere le derivate generalizzate di ordine superiore:
\begin{displaymath}
    \mathcal{L}[D^{*i}f] = s^i F(s) - s^{i-1}f_- - s^{i-2} Df_- -\dots-sD^{i-2}f_--D^{i-1}f_-
\end{displaymath}
\subsection{Estensione dell'insieme dei behaviors}
Dato un sistema dinamico $\Sigma$ descritto dall'eq. differenziale
\begin{displaymath}
    \sum_{i=0}^n a_i D^i  y = \sum_{i=0}^m b_i u
\end{displaymath}
si definisce estensione impulsiva dei behaviors o \textbf{behavior esteso}
\begin{displaymath}
    \mathcal{B}^* := \left\{(u,y) \in C_p^\infty (\mathbb{R})^* \times C_p^\infty (\mathbb{R})^* : \sum_{i=0}^n a_i D^{*i} y = \sum_{i=0}^m b_i D^{*i} u\right\}
\end{displaymath}
Ancora l'equazione differenziale è soddisfatta in senso distribuzionale per ogni $t \in \mathbb{R}$. 
\begin{displaymath}
    \mathcal{B} \subset \mathcal{B}^*
\end{displaymath}
\subsubsection{Proprietà}
\begin{itemize}
    \item Sia $(u,y)\in \mathcal{B}^*$, segue $(D^*u, D^*y)\in \mathcal{B}^*$.
    \item Proprietà della coppia azione forzante-risposta forzata: sia $(u,y) \in \mathcal{B}^*$ con $u(t)$ azione forzante e $y(t)$ risposta forzata. Segue 
    \begin{displaymath}
        \left(\int_{0-}^t u(v) dv,\int_{0-}^t y(v) dv\right) \in \mathcal{B}^*
    \end{displaymath}
\end{itemize}
\subsection{Il problema fondamentale dell'analisi del dominio nel tempo di un sistema $\Sigma$}
Note le condizioni iniziali al tempo $0-$  $y_-, Dy_-,...,D^{n-1}y_-$ e $u_-,Du_-,\dots,D^{m-1}u_-$ e l'azione forzante $u(t), t\ge0$, vogliamo determinare la risposta $y(t), t\ge0$.
Risolviamo quindi l'equazione differenziale di $\Sigma$
\begin{displaymath}
    \sum_{i=0}^n a_i D^{*i} y(t) = \sum_{i=0}^m b_i D^{*i} u(t)
\end{displaymath}
Applicando la trasformata di Laplace. Otterremmo una soluzione $y(t) = y_{for.}(t) + y_{lib.}(t), t\ge0$, ossia un'uscita composta da risposta forzata di $\Sigma$ all'azione forzante, e una risposta (evoluzione) libera di $\Sigma$.
\subsection{Funzione di trasferimento}
Definiamo ora la funzione di trasferimento di un sistema la funzione di variabile complessa $G(s)$ per la quale è valida la relazione
\begin{displaymath}
    \mathcal{L}[y(t)] = G(s)\mathcal{L}[u(t)]
\end{displaymath}
$\forall (u(t), y(t)) \in \mathcal{B}$ con $u(t)=0, y(t)=0$ per $t<0$.
Abbiamo quindi ottenuto un modello matematico alternativo all'eq. differenzialie:
\begin{displaymath}
    G(s)=\frac{\sum_{i=0}^m b_i s^i}{\sum_{i=0}^n a_i s^i}=\frac{b(s)}{a(s)}
\end{displaymath}
Se le condizioni iniziali sono tutte nulle (sistema in quiete per $0-$), $Y(s)=G(s)U(s)\rightarrow Y_{for.}(s)=G(s)U(s)$ (trasformata della risposta forzata). Sia $g(t):=\mathcal{L}^{-1} [G(s)]$ con $g(t)=0, t<0: g(t)$ è la \textbf{risposta all'impulso} a partire da una condizione di quiete $(\delta(t), g(t)) \in \mathcal{B}^*$. Dal teorema di convoluzione sappiamo che $y_{for.}(t) = \int_0^t g(t-v)u(v)dv$. Otteniamo quindi la \textbf{soluzione generale dell'equazione differenziale} ($t\ge0$):
\begin{displaymath}
    y(t)=\int_0^t g(t-v)u(v)dv + \mathcal{L}^{-1}\left[\frac{\sum_{i=1}^n \sum_{j=0}^{i-1}a_i D^{i-1-j}y_- s^j - \sum_{i=1}^{m} \sum_{j=0}^{i-1} b_i D^{i-1-j}u_- s^j}{\sum_{i=0}^n a_is^i}\right]
\end{displaymath}
\subsection{Definizioni}
\subsubsection{Proprio}
Un sistema $\Sigma$ si dice \textbf{(strettamente) proprio} se la sua funzione di trasferimento è \textbf{(strettamente) propria}. Quindi, con $n\ge m (\rho \ge 0)$ abbiamo $\Sigma$ proprio, se $n>m (\rho\ge1)$ strettamente proprio.
\subsubsection{Guadagno statico}
Definiamo il \textbf{guadagno statico di $\Sigma$} come il rapporto fra il valore costante dell'uscita e il valore costante dell'ingresso ($\neq 0$) quando $\Sigma$ è all'equilibrio:
\begin{displaymath}
    K := \frac{y_c}{u_c} \textrm{ con } (u_c, y_c) \in \mathcal{B} \textrm{ e }u_c \neq 0
\end{displaymath}
Dall'equazione differenziale otteniamo $K=\frac{b_0}{a_0} \rightarrow K=G(0)$.
\subsubsection{Polinomio caratteristico di $\Sigma$}
Dato il sistema $\Sigma$ descritto dall'eq. differenziale $\sum_{i=0}^n a_i D^i y = \sum_{i=0}^m b_i D^i u$, il polinomio $a(s)= \sum_{i=0}^n a_i s^i$ è detto polinomio caratteristico di $\Sigma$. È utile notare che esso è il polinomio a denominatore della funzione di trasferimento.
\subsubsection{Poli e zeri}
I poli e zeri di $\Sigma$ sono i poli e gli zeri della funzione di trasferimento. 
\subsubsection{Modi del sistema dinamico $\Sigma$}
I \textbf{modi} sono le funzioni  "tipiche" associate ai poli di $\Sigma$ secondo la regola:
\begin{center}
    Se $p$ è un polo reale di molteplicità $h$: $e^{pt}, te^{pt},\dots, t^{h-1}e^{pt}$
\end{center}
\begin{center}
    Se $\sigma+j\omega$ è una coppia di poli complessi coniugati di molteplicità $h$: $e^{\sigma t} sen(\omega t+\phi_1), te^{\sigma t} sen(\omega t+\phi_2),\dots, t^{h-1}e^{\sigma t} sen(\omega t+\phi_h)$ oppure equivalentemente $e^{\sigma t} sen(\omega t), e^{\sigma t} cos(\omega t), te^{\sigma t} sen(\omega t), te^{\sigma t} cos(\omega t),\dots, t^{h-1}e^{\sigma t} sen(\omega t), t^{h-1} e^{\sigma t} cos(\omega t)$
\end{center}

\subsubsection{Risposta libera e modi di $\Sigma$}
Sia $\Sigma$ un sistema per il quale i poli coincidono con le radici del polinomio caratteristico ($a(s)$ e $b(s)$ coprimi fra loro). Allora la risposta libera è una combinazione lineare dei suoi modi. 
\subsubsection{Razionalità}
Non tutti i sistemi dinamici lineari e stazionari sono caratterizzati da funzioni di trasferimento razionali. Un esempio è il ritardo finito.
\subsubsection{Segnali tipici per l'ingresso di $\Sigma$}
Alcuni segnali tipici di ingresso:
\begin{itemize}
    \item $\delta(t)$ impulso unitario (delta di Dirac): $\mathcal{L}[\delta (t)] = 1$
    \item $1(t)$ gradino unitario: $\mathcal{L}[1(t)] = \frac{1}{s}$
    \item $t\cdot 1(t)$ rampa unitaria: $\mathcal{L}[t\cdot 1(t)] = \frac{1}{s^2}$
    \item $\frac{1}{2}t^2 \cdot 1(t)$ parabola unitaria: $\mathcal{L}\left[\frac{1}{2}t^2 \cdot 1(t)\right] = \frac{1}{s^3}$
\end{itemize}
\subsubsection{Risposta canonica}
La risposta canonica è la risposta forzata di $\Sigma$ a un segnale tipico di ingresso. Quelle usualmente adottate sono $g(t)$, la risposta all'impulso, detta anche \textbf{risposta impulsiva}, e $g_s(t)$, la risposta al gradino $1(t)$ detta \textbf{risposta indiciale}. Sappiamo inoltre che 
\begin{displaymath}
    g(t) = \mathcal{L}^{-1}[G(s)] \hspace{10px} g_s(t) = \mathcal{L}^{-1}\left[\frac{1}{s}G(s)\right]
\end{displaymath}
Una proprietà interessante è che
\begin{displaymath}
    \int_{0-}^t g(v) dv = g_s(t) \hspace{10px} g(t)=D^* g_s (t)
\end{displaymath}
Per i sistemi strettamente propri, $g(t) = Dg_s(t^+)$.
\subsubsection{Integrali di Vaschy}
Nota la risposta al gradino $g_s(t)$, la risposta forzata $y_{for} (t), t\ge0$ effetto dell'azione forzante $u(t), t\ge0$ è determinabile come 
\begin{displaymath}
    y_{for}(t) = \int_0^t u' (v) g_s(t-v) dv + u(0+)g_s(t)
\end{displaymath}
\begin{displaymath}
    y_{for}(t) = \int_0^t  g_s(v) u'(t-v) dv + u(0+)g_s(t)
\end{displaymath}
\section{Sistemi dinamici elementari}
Con questa lezione ci poniamo due obiettivi: studiare le caratteristiche dei sistemi lineari più semplici (primo ordine con grado relativo uno e secondo ordine con grado relativo due) e semplificare i sistemi di più complessi comparandoli a sistemi di secondo ordine. 
\subsection{Sistemi del primo ordine (strettamente propri)}
Un sistema del primo ordine strettamente proprio è definito da $G(s)=\frac{1}{1+\tau s}$ (guadagno statico normalizzato a 1), equazione differenziale $\tau Dy + y = u$ con $\tau$ costante di tempo ($>0$). Ha un polo ($-\frac{1}{\tau}$) e un modo ($e^{-\frac{1}{\tau}t}$). Per determinare la risposta al gradino unitario $g_s(t)$ svolgiamo l'antitrasformata:
\begin{displaymath}
    g_s(t) = \mathcal{L}^{-1}\left[\frac{1}{1+\tau s}\frac{1}{s}\right] = 1 - e^{-t/\tau}, t\ge0
\end{displaymath}
\subsubsection{Parametri della risposta al gradino}
Spesso la risposta al gradino unitario di un sistema dinamico generico ha un andamento caratteristico, dove distinguiamo alcuni parametri:
\begin{itemize}
    \item $S$ massima sovraelongazione (in \% del valore di regime)
    \item $T_r$ tempo di ritardo
    \item $T_s$ tempo di salita
    \item $T_m$ istante di massima sovraelongazione 
    \item $T_a$ tempo di assestamento $inf\left\{T>0: |g_s(t)-y_{regime}|\le 0,05 y_{regime} \forall t \ge T\right\}$
\end{itemize}
\subsection{Sistemi del secondo ordine (senza zeri)}
La funzione di trasferimento $G(s)$ sia così parametrizzata:
\begin{displaymath}
    G(s)=\frac{\omega^2_n}{s^2+2\delta\omega_n s + \omega_n^2}, G(0)=1
\end{displaymath}
Con equazione differenziale
\begin{displaymath}
    D^2(y)+2\delta\omega_n Dy + \omega^2_n y = \omega_n^2 u
\end{displaymath}
dove $\omega_n$ è la pulsazione naturale, mentre $\delta$ è il coefficiente di smorzamento, $\in (0,1)$.
Poli e zeri sono definiti da:
\begin{displaymath}
    \left\{\textrm{poli di }G(s)\right\} = \left\{-\delta\omega_n \pm j\omega_n \sqrt{1-\delta^2}\right\} \hspace{10px}\left\{\textrm{modi di }G(s)\right\} = \left\{e^{-\delta\omega_nt}sen\left(\omega_n\sqrt{1-\delta^2}t+\phi_1\right)\right\}
\end{displaymath}
Determiniamo la risposta al gradino unitario, come sempre, con l'antitrasformata:
\begin{displaymath}
    y(t)=\mathcal{L}^{-1}\left[\frac{\omega_n^2}{s(s^2 + 2\delta\omega_n s+\omega_n^2)}\right] = 1-Ae^{-\delta\omega_nt} sen(\omega t + \phi)
\end{displaymath}
\begin{displaymath}
    \omega := \omega_n \sqrt{1-\delta^2}\hspace{10px}A:=\frac{1}{\sqrt{1-\delta^2}}\hspace{10px}\phi:=arccos(\delta)
\end{displaymath}
Notiamo che per $\delta=1, A$ tende ad infinito quindi bisogna ricalcolare l'antitrasformata. La massima sovraelongazione $S$ è invece pari a
\begin{displaymath}
    S = 100exp\left\{-\frac{\delta \pi}{\sqrt{1-\delta^2}}\right\}
\end{displaymath}
I tempi di asservimento e salita, invece:
\begin{displaymath}
    T_a \cong \frac{3}{\delta\omega_n}\hspace{10px}T_s \approx \frac{1,8}{\omega_n}
\end{displaymath}
Com'è evidente, la seconda è approssimata, frutto di interpolazione.
\subsection{Poli dominanti di un sistema generico}
Un sistema $\Sigma$ generico con funzione di trasferimento $G(s)=\frac{b(s)}{a(s)}$, con n poli e $m$ zeri, tutti i poli hanno parte reale negativa (i modi convergono a zero per $t\rightarrow+\infty$). Definiamo i \textbf{poli dominanti} come i poli (normalmente una coppia) non soggetti a quasi cancellazione polo-zero, più vicini all'asse immaginario. La risposta al gradino unitario dipende approssimativamente dai soli poli dominanti: se i poli dominanti sono complessi coniugati, i parametri della risposta $S, T_a, T_s$ sono determinabili approssimativamente dalle relazioni per i sistemi di ordine due. Bisogna però fare attenzione: spesso può essere un'approssimazione abbondante, e non sempre è possibile individuare un insieme significativo di poli dominanti. 
\subsection{Specifiche sulla risposta al gradino per un sistema di controllo}
Siamo ora in grado di poter definire delle specifiche sulla risposta al gradino grazie ai parametri definiti: imponiamo infatti le specifiche $S \le S_{max}$ e $T_a \le T_{a-max}$, ottenendo che i poli $-\delta\omega_n \pm j\omega_n \sqrt{1-\delta^2}$ devono appartenere ad un cono troncato.

\section{La stabilità dei sistemi dinamici}
\subsection{Stabilità alle perturbazioni}
Consideriamo un sistema dinamico $\Sigma$ nella solita forma $\sum_{i=0}^n a_i D^i y = \sum_{i=0}^m b_i D^i u$ e andiamo ad analizzarne i punti di equilibrio, ossia quei valori costanti di ingresso/uscita che si mantengono inalterati nel tempo. Andiamo quindi ad analizzare una coppia di valori $u_c, y_c$ devono rispettare la relazione $y_c = G(0)u_c$. Possiamo quindi mettere i punti a grafico, che evidentemente staranno su una retta con pendenza data dal guadagno statico $\frac{b_0}{a_0}$.
Introduciamo il concetto di stabilità. Per semplicità ci concentreremo solo sul punto di equilibrio che sta nell'origine. Ipotizziamo anche che $a(s)$ e $b(s)$ siano coprimi (non hanno radici in comune). Esaminiamo una perturbazione alla condizione di equilibrio, ad esempio introducendo un segnale di ingresso o modificando l'uscita nell'intervallo $[t_0,0)$. 
Distinguiamo tra tre tipologie di risposta a questa condizione: instabilità, stabilità semplice, stabilità asintotica. Formalizziamo la perturbazione come
\begin{displaymath}
    u(t) = 0 \textrm{ per }t<t_0, u(t) \neq 0 \textrm{ per }t\in[t_0, 0), u(t)=0 \textrm{ per }t\ge0
\end{displaymath}
\begin{displaymath}
    y(t) = 0 \textrm{ per }t<t_0, y(t) \neq 0 \textrm{ per }t\in [t_0,0), y(t)=y_{lib}(t) \textrm{ per }t\ge0
\end{displaymath}
Di conseguenza, l'uscita è in evoluzione libera per $t\ge0$.
Torniamo alla classificazione precedente:
\begin{itemize}
    \item $y_{lib}(t)$ è limitata su $[0,+\infty)$ punto di equilibrio \textbf{stabile}
    \item $y_{lib}(t)$ non è limitata su $[0,+\infty)$ punto di equilibrio \textbf{instabile}
    \item Se è stabile e convergente a $0$ per $t\rightarrow+\infty$ punto di equilibrio \textbf{asintoticamente stabile}
    \item È \textbf{semplicemente stabile} se è stabile ed esiste una perturbazione per la quale \begin{displaymath}
        lim_{t\rightarrow+\infty}y_{lib}(t)=y_\infty \neq 0 \vee \left\{\textrm{non esiste} lim_{t\rightarrow+\infty} y_{lib}(t)\right\}
    \end{displaymath} 
\end{itemize}
\begin{center}
    Per il sistema lineare $\Sigma$, il comportamento della risposta libera a seguito di perturbazioni su di un punto, rimane il medesimo per tutti gli altri punti. Possiamo quindi parlare di stabilità del sistema piuttosto che del singolo punto.
\end{center}
\subsection{Teorema sui poli e la stabilità}
La stabilità è strettamente legata ai poli del sistema. Consideriamo un sistema $\Sigma$ lineare per il quale i poli coincidono con le radici del polinomio caratteristico ($a(s)$ e $b(s)$ coprimi). Valgono le seguenti condizioni necessarie e sufficienti:
\begin{itemize}
    \item $\Sigma$ è \textbf{stabile} se e solo se tutti i poli hanno parte reale non positiva e gli eventuali poli puramente immaginari sono semplici
    \item $\Sigma$ è \textbf{asintoticamente stabile} se e solo se tutti i suoi poli hanno parte reale negativa
    \item $\Sigma$ è \textbf{semplicemente stabile} se e solo se tutti i poli hanno parte reale non positiva e quelli puramente immaginari (che devono esistere, al massimo è $s=0$) sono semplici 
    \item $\Sigma$ è \textbf{instabile} se e solo se esiste almeno un polo a parte reale positiva o un polo puramente immaginario con molteplicità maggiore di 1.
\end{itemize}
\subsection{Stabilità bounded-input bounded-output}
La cosiddetta \textbf{stabilità BIBO} è così definita:
\begin{center}
    $\Sigma$ è BIBO stabile se per ogni azione forzante limitata la corrispondente risposta forzata è limitata.
\end{center}
Formalmente, è BIBO stabile se per ogni azione forzante la cui norma infinito $||u(t)||_\infty$ sia $<+\infty$, la norma infinito della risposta forzata $||y(t)||_\infty$ generata sia $<+\infty$.
Grazie a un teorema, possiamo affermare che $\Sigma$ è BIBO stabile se e solo se 
\begin{displaymath}
    \int_0^{+\infty} |g(\tau)|d\tau < +\infty
\end{displaymath}
Un altro teorema utile è il seguente. Assumiamo $a(s)$ e $b(s)$ coprimi. Vale la seguente equivalenza:
\begin{center}
    Il sistema $\Sigma$ è BIBO stabile se e solo se $\Sigma$ è asintoticamente stabile. 
\end{center}
I due concetti vengono spesso utilizzati equivalentemente.
\subsection{Criterio di Routh}
Partiamo da una premessa: abbiamo fino ad ora associato la stabilità ai poli del sistema dinamico. Questi ultimi sono le radici dell'equazione caratteristica: potremo dire che con routine numeriche possiamo risolvere i quesiti sulla stabilità. Questo è spesso opportuno, ma è anche utile saperlo fare senza calcolo di radici. Consideriamo il solito sistema lineare $\Sigma$ decritto da $\sum_{i=0}^n a_i D^i y = \sum_{i=0}^m b_i D^i u$ con f.d.t. $G(s)= \frac{b(s)}{a(s)}$, con $a(s)$ polinomio caratteristico e relativa equazione caratteristica $a_s=0$:
\begin{displaymath}
    a_ns^n+a_{n-1}s^{n-1}+...+a_1s+a_0=0
\end{displaymath}
Vediamo una prima proprietà, ricordando anzitutto cos'è un polinomio di Hurwitz: un polinomio $a(s)$ è detto tale se tutte le radici hanno parte reale negativa. Assumiamo ora $a_n>0$; il polinomio è hurwitziano solo se tutti i suoi coefficienti sono positivi. Non è sempre vero il contrario. Lo dimostriamo fattorizzando in modo estensivo $a(s)$ con dei fattori $(s+\eta_i)$.
È possibile determinare il segno delle radici di $a(s)$ attraverso una \textbf{tabella di Routh}, senza doverle effettivamente calcolare. La tabella è costituita da $n-1$ righe, calcolate a ritroso. Le prime due righe contengono i coefficienti alternati del polinomio $a(s)$. In assenza di abbastanza coefficienti, riempiamo con 0. A questo punto, la terza riga viene calcolata a partire dalle due righe superiori. La quarta si baserà anch'essa sulle due righe superiori, a ritroso fino al calcolo di $\gamma_{n,1}$. Per calcolare i coefficienti delle righe dopo la seconda:
\begin{displaymath}
    y_{k,j}=-\frac{\begin{vmatrix}
        \gamma_{k-2,1} & \gamma_{k-2,j+1}\\
        \gamma_{k-1,1} & \gamma_{k-1,j+1}
    \end{vmatrix}}{\gamma_{k-1,1}}
    = \frac{\gamma_{k-1,1}\gamma_{k-2,j+1} - \gamma_{k-2,1}\gamma_{k-1,j+1}}{\gamma_{k-1,1}}
\end{displaymath}
La riga finisce quando il determinante è 0. 
\subsubsection{Teorema di Routh}
Per applicare il criterio, andiamo ad esaminare la prima colonna, osservando le variazioni di segno nella colonna. Determiniamo il numero di variazioni/permanenze, che sommate daranno $n$. 
Assumiamo che la tabella di Routh possa essere completata (assenza di singolarità). Allora, ad ogni variazione di segno corrisponde una radice a parte reale positiva, ad ogni permanenza corrisponde una radice a parte reale negativa.
\subsubsection{Criterio di Routh}
Il polinomio $a(s)$ è hurwitziano se e solo se l'associata tabella di Routh può essere completata (con l'algoritmo base) e presenta nella prima colonna solo permanenze di segno. 
\subsubsection{Proprietà della tabella}
I termini di una riga possono essere moltiplicati tutti per uno stesso coefficiente senza che ciò modifichi le variazioni/permanenze di segno della prima colonna. 
\subsubsection{Singolarità della tabella}
Distinguiamo due tipi di singolarità possibili:
\begin{enumerate}
    \item Il primo elemento di una riga è zero 
    \item Tutti gli elementi di una riga sono nulli
\end{enumerate}
Esistono metodi ad hoc per risolvere queste singolarità. 
\paragraph{Prosecuzione della tabella nel caso 1} Per il primo tipo di singolarità, citiamo due metodi: 
\begin{enumerate}
    \item Metodo $\epsilon$, obsoleto perché non sempre risolutivo e complesso: inserire un numero arbitrario $\epsilon$ sullo 0
    \item Metodo di Benidir-Picinbono: algoritmicamente semplice e sempre risolutivo
\end{enumerate}
Vediamo il secondo: ogni riga non nulla che inizia con $p$ zeri viene sommata con la riga ottenuta moltiplicandola per $-1^p$ e traslandola verso sinistra di $p$ posizioni. 
0\paragraph{Prosecuzione della tabella nel caso 2} Questo accade sempre in una riga dispari: il polinomio non ha radici nell'origine ($a_0 \neq 0$). Introduciamo un polinomio ausiliario $\beta$ ottenuto riportando le potenze pari di $s$:
\begin{displaymath}
    \beta(s) := \gamma_{n-2i,1}s^{2i}+\gamma_{n-2i,2}s^{2i-2}+\gamma_{n-2i,3}s^{2i-4}+\dots+\gamma_{n-2i,i}s^{2}+\gamma_{n-2i,i+1}
\end{displaymath}
L'equazione ausiliaria è quindi $\beta(s) = 0$.
Il polinomio ausiliario $\beta(s)$ divide $a(s)$. Esiste quindi un polinomio $a(s)$ tale che $a(s) = \alpha(s)\beta(s)$. Inoltre, la prima parte di tabella dà informazioni sul segno delle radici di $\alpha(s)$. Enunciamo anche la proprietà di simmetria delle radici del polinomio ausiliario: queste radici sono disposte simmetricamente rispetto all'origine del piano complesso. Se ad esempio avessi una radice positiva in $+3$, il polinomio ausiliario avrà radice in $-3$. Il numero di radici a parte reale positiva di $\beta(s)$ sarà quindi uguale al suo numero di radici a parte reale negativa. Può anche presentare radici puramente immaginarie. Come proseguire la costruzione della tabella?
\begin{enumerate}
    \item Si fa la derivata del polinomio ausiliario 
    \item Sostituisco gli zeri della riga nulla coi coefficienti del polinomio ausiliario derivato 
    \item Nel conteggio, le variazioni avranno lo stesso significato (radice a parte reale positiva), mentre le permanenze potranno essere associate a radici a parte reale negativa o radici puramente immaginaria.
\end{enumerate}
Insomma: \textbf{la simmetria delle radici di $\beta(s)$ permette di stabilire il segno della parte reale di tutte le radici}.
Concludiamo facendo notare che il criterio di Routh viene utile anche quando lo applichiamo in funzione di parametri del sistema: otteniamo così un sistema di disequazioni che ci permette di progettare un sistema di controllo.
\section{Analisi armonica e diagrammi di Bode}
Ma anzitutto, cos'è il fenomeno armonico? Per spiegarlo, prendiamo una f.d.t. $G(s) = \frac{10}{s+1}$ e applichiamo il segnale armonico $u(t) = 2sin(t)$. Calcoliamo $Y(s)=\frac{10}{s+1}(s)\mathcal{L}[2sin(t)]$, poi calcoliamo i $k_i$. Risolviamo e notiamo che la risposta forzata è data da una parte transiente, ed una parte armonica. Concludiamo che quando $t\rightarrow+\infty$ scompare la parte armonica e quindi vale $y_\infty(t) = 10\sqrt{2sin\left(t-\frac{\pi}{4}\right)}$. Questa proprietà è generalizzabile. Fenomeno di risposta armonica:
\begin{center}
    Col sistema in quiete, all'istante $t=0-$, si applichi $u(t)=Usin(\omega t)$. La risposta forzata di $\Sigma$ assume questa forma: $y_\infty(t) = Y(\omega) sen(\omega t + \phi(\omega))$
\end{center}
Possiamo così definire una funzione di risposta armonica, che sarà $\mathbb{R}_{\ge0}\rightarrow\mathbb{C}$. In particolare associamo ad $\omega$ un valore $F(\omega)=\frac{Y(\omega)}{U}e^{j\phi(\omega)}$. In virtù della linearità di $\Sigma$, $F(\omega)$ è indipendente da U (grazie al principio di sovrapposizione degli effetti).
Enunciamo così un teorema.
\paragraph{Teorema di analisi armonica}
Sia $\Sigma$ un sistema asintoticamente stabile con f.d.t. $G(s)$ razionale. La risposta forzata di $\Sigma$ ad un segnale armonico all'ingresso è ancora, a regime $t\rightarrow+\infty$, un segnale armonico con la stessa frequenza dell'ingresso. La funzione di risposta armonica associata soddisfa la relazione:
\begin{displaymath}
    F(\omega) = G(j\omega)
\end{displaymath}
Ovvero coincide con la funzione di trasferimento $G(s)$, valutata in $s=j\omega$.
Alcune considerazioni necessarie:
\begin{itemize}
    \item La funzione di risposta armonica è un modello matematico alternativo all'eq. diff., f.d.t\dots 
    \item Può essere determinata sperimentalmente
    \item Sfruttando la relazione $F(\omega) = G(j\omega)$ la f. di risposta armonica è definibile anche per sistemi non asintoticamente stabili: in questo caso la risposta armonica descrive una soluzione instabile delle armoniche nel sistema.
    \item Relazioni fra la risposta armonica $G(j\omega)$ e la risposta all'impulso $g(t)$:\begin{displaymath}
        \begin{cases}
            G(j\omega) = \int_{0-}^{+\infty} g(t)e^{-j\omega t}dt \\
            g(t) = \frac{1}{2\pi}\int_{-\infty}^{+\infty} G(j\omega)e^{j\omega t}d\omega
        \end{cases}
    \end{displaymath}
    Queste sono trasformate di Fourier. La prima è ottenibile dalla definizione di trasformata di Laplace, sostituendo $j\omega$ ad $s$. La seconda si ricava dalla formula di antitrasformazione di Laplace, facendo un integrale di linea. 
    \item Ponendo $G(j\omega) = R(\omega) + jI\omega$ (parte reale ed immaginaria) 
    \item Rappresentazioni grafiche della funzione di risposta armonica: diagrammi di Bode, diagrammi di Nyquist (polari), diagrammi di Nichols.
\end{itemize}

\subsection{Guadagni del sistema lineare $\Sigma$}
Abbiamo quindi individuato tre guadagni relativi al sistema stesso:
\begin{itemize}
    \item Funzione di trasferimento $G(s)$ (guadagno dinamico)
    \item Ponendo $s:=j\omega$, otteniamo la funzione di risposta armonica $\rightarrow G(j\omega)$ o risposta in frequenza 
    \item Ponendo $s:=0$ otteniamo il guadagno statico $G(0)$
\end{itemize}
\subsection{I diagrammi di Bode}
I \textbf{diagrammi di Bode} sono diagrammi (cartesiani) logaritmici della risposta armonica. In particolare, riportiamo dalla rappresentazione polare di $G(j\omega)$ e applichiamo il logaritmo naturale. Spesso si indicano parte reale e immaginaria come $\alpha, beta$. Andremo quindi a mettere a grafico il \textbf{diagramma delle ampiezze}, che riporta il logaritmo del modulo della r.a. in funzione del logaritmo della pulsazione $\omega$, ed il \textbf{diagramma delle fasi} che riporta l'argomento della r.a. in funzione del logaritmo della pulsazione $\omega$.
Usualmente, nelle ascisse, vengono riportati direttamente i valori delle pulsazioni ed i moduli in scala logaritmica. Può capitare che nel diagramma dei moduli, le ordinate (modulo della r.a.) siano espresse in decibel. La scala logaritmica ha diversi vantaggi: è possibile rappresentare grandezze variabili in campi molto estesi, è possibile sommare i diagrammi dei sistemi in cascata, ed è anche possibile costruire i diagrammi come somme di diagrammi elementari. 
\subsection{Rappresentazioni e parametri della f.d.t.}
Una f.d.t. razionale $G(s)=\frac{b(s)}{a(s)}$ scrivibile nella \textbf{forma standard con polinomi monici}:
\begin{displaymath}
    G(s)=K_1\frac{s^m+b_{m-1}s^{m-1}+...+b_0}{s^n+a_{n-1}s^{n-1}+\dots+a_0}
\end{displaymath}
o nella \textbf{forma standard con poli e zeri}:\begin{displaymath}
    G(s)=K_1\frac{(s-z_1)(s-z_2)...(s-z_m)}{(s-p_1)(s-p_2)...(s-p_n)}
\end{displaymath}
Con $K_1$ costante di trasferimento. A partire dalla seconda forma possiamo fare un'altra elaborazione parametrica: ipotizziamo la presenza di un polo nell'origine di molteplicità $h$ ("tipo" del sistema in oggetto)
\begin{displaymath}
    G(s)=K_1\frac{(s-z_1)...(s-z_m)}{s^h(s-p_{h+1})...(s-p_n)}
\end{displaymath}
Fatto ciò possiamo separare i poli/zeri fra reali e complessi coniugati. Otteniamo quindi 
\begin{displaymath}
    G(s) = K_1\frac{\left(s+\frac{1}{\tau'_1}\right)\left(s+\frac{1}{\tau'_2}\right)\dots(s^2+2\delta'_1\omega'_{n1}s + \omega^{'2}_{n1})(s^2+2\delta'_2\omega'_{n2}s + \omega^{'2}_{n2})}{s^h\left(s+\frac{1}{\tau_1}\right)\left(s+\frac{1}{\tau_2}\right)\dots(s^2+2\delta'_1\omega'_{n1}s + \omega^{'2}_{n1})(s^2+2\delta'_2\omega'_{n2}s + \omega^{'2}_{n2})}
\end{displaymath}
Con $\tau_i$ costante di tempo assoluta ad un polo (zero) reale, $\tau_i<0$ se il polo/zero è positivo. $\omega_{ni}$ pulsazione naturale assoluta ad una coppia di poli/zeri complessi coniugati. $\delta_i$ coefficiente di smorzamento assoluto ad una coppia di poli/zeri complessi coniugati. Notiamo quindi che l'espressione è divisibile in un parte dovuta ai poli/zeri reali e una ai complessi coniugati. Osserviamo che tutte le coppie di complessi coniugati vengono parametrizzate attraverso dei polinomi di secondo ordine. A questo punto possiamo raccogliere le costanti $\tau$ e gli $\omega$. Otteniamo quindi la scrittura della $G(s)$ seguente:
\begin{displaymath}
    G(s)=K_1\frac{\omega^{'2}_{n1}\omega^{'2}_{n2}...\tau_1\tau_2...}{\omega^{2}_{n1}\omega^{2}_{n2}...\tau_1^{'}\tau_2^{'}...} \cdot \frac{(1+\tau_1^{'}s)(1+\tau_2^{'}s)\dots\left(1+2\delta^{'}_1 \frac{s}{\omega^{'}_{n1}}+\frac{s^2}{\omega^{'2}_{n1}}\right)}{s^h(1+\tau_1s)(1+\tau_2s)\dots\left(1+2\delta_1 \frac{s}{\omega_{n1}}+\frac{s^2}{\omega^{2}_{n1}}\right)}
\end{displaymath}
Raccogliamo il primo fattore come $K=K_1\frac{\omega^{'2}_{n1}\omega^{'2}_{n2}...\tau_1\tau_2...}{\omega^{2}_{n1}\omega^{2}_{n2}...\tau_1^{'}\tau_2^{'}...} $, e otteniamo la \textbf{forma standard con le costanti di tempo:}
\begin{displaymath}
    G(s)=K\frac{(1+\tau_1^{'}s)(1+\tau_2^{'}s)\dots\left(1+2\delta^{'}_1 \frac{s}{\omega^{'}_{n1}}+\frac{s^2}{\omega^{'2}_{n1}}\right)}{s^h(1+\tau_1s)(1+\tau_2s)\dots\left(1+2\delta_1 \frac{s}{\omega_{n1}}+\frac{s^2}{\omega^{2}_{n1}}\right)}
\end{displaymath}
Con $K$ costante di guadagno, che in base ad $h$ è:
\begin{itemize}
    \item $h=0$ $K$ è guadagno statico
    \item $h=1$ $K$ è guadagno di velocità
    \item $h=2$ $K$ è guadagno di accelerazione
\end{itemize}
Sostituiamo ora $j\omega$ ad $s$ per trovare la risposta armonica con le costanti di tempo. 
\subsection{Diagrammi elementari}
Vogliamo tracciare il diagramma di Bode partendo dai diagrammi elementari: $K, (j\omega)^{-h}, (1+\tau j \omega)^{\pm 1}, \left(1-\frac{\omega^2}{\omega^2_n}+2\delta \frac{j\omega}{\omega_n}\right)^{\pm1}$. Il $\pm1$ dipende da se si tratta di zeri complessi coniugati o poli complessi coniugati. 
Prima di ciò definiamo alcuni parametri caratteristici:
\begin{itemize}
    \item Pulsazione di risonanza $\omega_R := arg max_{\omega \in \mathbb{R}_{\ge0}}|G(j\omega)|$
    \item Picco di risonanza $M_R := \frac{|G(j\omega_R)|}{|G(j0)|}$ oppure $M_R := |G(j\omega_R)|$
    \item Larghezza di banda $B_\omega := \omega_{t2} - \omega_{t1}$ ossia la differenza tra pulsazione di taglio superiore e di taglio inferiore
\end{itemize}
SLIDE A.

SLIDE B.

SLIDE C.

Qui, $\frac{1}{\tau}$ è detta anche pulsazione d'angolo. Possiamo inoltre, nel diagramma delle fasi, tracciare la tangente del diagramma delle pulsazioni. Otteniamo così un segmento che si raccorda coi due tratti asintotici identificati da $\omega_a$ e $\omega_b$. Vogliamo quindi determinare i valori dei suddetti per poter tracciare il diagramma.
Sappiamo che $\beta = -arctg \omega \tau$. Deriviamo ora $\beta$ rispetto al logaritmo naturale di $\omega$.
\begin{displaymath}
\frac{d\beta}{d(ln\omega)}|_{\omega=\omega_0} = -\frac{1}{2}
\end{displaymath} 
che è la pendenza della tangente. Otteniamo quindi che 
\begin{displaymath}
    \frac{\pi/4}{ln\omega_0-ln\omega_a}=\frac{1}{2} \rightarrow ln\frac{\omega_0}{\omega_a} \rightarrow e^{\frac{\pi}{2}} \cong 4,81
\end{displaymath}
Sappiamo quindi che $\omega_a = \frac{\omega_0}{4,81}$ e $\omega_b = \omega_0 4,81$. I diagrammi di $G(j\omega) = q+j\omega\tau$ si ottengono per simmetria ribaltando i precedenti rispetto all'asse delle ascisse. 
SLIDE D.
Per determinare il picco di risonanza $\omega_R$ sfruttiamo, solo quando $1-2\delta^2 >0$, $\omega_R = \omega_n\sqrt{1-2\delta^2}$. Quindi, inserendo il valore appena calcolato di $\omega_R$ in $M_R$:
\begin{displaymath}
    M_R = \frac{|G(j\omega_R)|}{|G(j0)|} = \frac{1}{2\delta\sqrt{1-\delta^2}}
\end{displaymath}
\begin{displaymath}
    \begin{cases}
        \delta \in \left(0,\frac{1}{\sqrt{2}}\right) \textrm{ c'è risonanza}\\
        \delta \in \left[\frac{1}{\sqrt{2}},1\right] \textrm{ non c'è risonanza}
    \end{cases}
\end{displaymath}
Possiamo anche fare un'altra osservazione:
\begin{displaymath}
    \begin{cases}
        \delta \in \left[0,\frac{1}{2}\right] \textrm{il d. }\alpha\textrm{ è tutto al di sopra del d. asintotico}\\
        \delta \in \left(\frac{1}{2},\frac{1}{\sqrt{2}}\right) \textrm{il d. }\alpha\textrm{ intersexa l'asse delle pulsazioni a sinistra di }ln\omega_n(\omega_n)\\
        \delta \in \left[\frac{1}{\sqrt{2}},1\right] \textrm{il d. }\alpha\textrm{ è tutto al di sotto del d. asintotico}\\
    \end{cases}
\end{displaymath}
Potremmo chiederci perché in $\delta=0$ il diagramma diverge. Questo succede perché esistono $c_1,c_2, \phi_1, \phi_2$ per cui otteniamo una risposta armonica con ampiezza divergente all'infinito $y(t)=c_1sen(\omega_nt+\phi_1)+c_2t(\omega_nt+\phi_2)$. Infine, calcoliamo la larghezza di banda:
\begin{displaymath}
    B_\omega = \omega_n\sqrt{(1-2\delta^2)+\sqrt{(1-2\delta^2)^2 +1}}
\end{displaymath}
Notiamo che i diagrammi di $G(j\omega) = 1-\frac{\omega^2}{\omega^2_n}+2\delta\frac{j\omega}{\omega_n}$ si ottengono ribaltando i precedenti rispetto all'asse delle ascisse. Se $\delta<0$, si ribalta il diagramma delle fasi.
\section{I diagrammi di Nyquist e i sistemi a fase minima}
\subsection{I diagrammi di Nyquist}
\subsubsection{Definizione}
Vediamo ora un'altra rappresentazione grafica delle risposte armoniche.
Definiamo subito un diagramma polare (di Nyquist) della risposta armonica $G(j\omega)$ o della f.d.t. $G(s)$ come la curva tracciata sul piano complesso dal vettore $G(j\omega)$ per $\omega$ che varia da $0$ a $+\infty$. 
Questi diagrammi sono utili per lo studio della stabilità, ad esempio tramite il criterio di Nyquist. Il tracciamento del diagramma può essere coadiuvato dal seguente procedimento grafico:
\begin{displaymath}
    G(s)=K_1\frac{(s-z_1)}{(s-p_1)(s-p_2)(s-p_3)} \hspace{10px}G(j\omega) = K_1 \frac{(j\omega-z_1)}{(j\omega-p_1)(j\omega-p_2)(j\omega-p_3)}
\end{displaymath}
\begin{displaymath}
    |G(j\omega)| = |K_1|\frac{M_1}{M_2M_3M_4} \hspace{10px}argG(j\omega) = \begin{cases}
    \varphi_1 - \varphi_2 - \varphi_3 - \varphi_4 \textrm{ se }K_1>0\\
    \varphi_1 - \varphi_2 - \varphi_3 - \varphi_4 - \pi \textrm{ se }K_1<0
    \end{cases}
\end{displaymath}
\subsubsection{Comportamenti importanti}
Citiamo i comportamenti più importanti per il diagramma polare:
\paragraph{Comportamento per $\omega\rightarrow+\infty$} Il diagramma polare di un sistema strettamente proprio termina (per $\omega\rightarrow+\infty$) sull'origine tangente ad uno degli assi coordinati. 
\paragraph{Comportamento per $\omega\rightarrow0+$, $\Sigma$ di tipo 0} Il diagramma polare di un sistema di tipo zero (non ha poli nell'origine) parte da $\omega=0$ dal punto dell'asse reale $G(j0)=K=K_1(b_0/a_0)$
\paragraph{Comportamento per $\omega\rightarrow0+$, $\Sigma$ di tipo $\ge1$} 
Si rappresenti $G(j\omega)$ con la forma standard con le costanti di tempo e sia $\tau_a := \sum_i \tau_i^{'} - \sum_i \tau_i + \sum_i 2\frac{\delta_i^{'}}{\omega_{ni}}$. Vale 
\begin{displaymath}
    lim_{g\rightarrow0+} G(j\omega) = K\frac{1+j\omega\tau_a}{(j\omega)^h}
\end{displaymath}
Otteniamo anche il seguente corollario:
\paragraph{Comportamento asintotico del d.p. dei sistemi di tipo $h=1,2,3$}
Dall'espressione precedente otteniamo che se $h=1$, 
\begin{displaymath}
    lim_{g\rightarrow0+} G(j\omega) = K\tau_a - j\frac{K}{\omega}
\end{displaymath}
e il d.p. parte adiacente ad una semiretta della retta di eq. $x=K\tau_a$.
Se $h=2$, otteniamo:
\begin{displaymath}
    lim_{g\rightarrow0+} G(j\omega) = -\frac{K}{\omega^2} - j\frac{K\tau_a}{\omega}
\end{displaymath}
Osserviamo che la parte reale diverge ad infinito più velocemente della parte immaginaria. Questo risultato può essere interpretato come una curva parametrica, eliminando omega otteniamo che il d.p. parte adiacente ad un ramo della parabola di eq. $x=-\frac{1}{K\tau_a^2}y^2$.
Infine, se $h=3$, vale 
\begin{displaymath}
    lim_{g\rightarrow0+} G(j\omega) = -\frac{K\tau_a}{\omega^2} + j\frac{K}{\omega^3}
\end{displaymath}
Notiamo che entrambe le componenti reali e immaginarie divergono ad infinito, con l'immaginaria che lo fa più velocemente, e individuiamo che il d.p. parte adiacente ad un ramo della curva cubica di eq. $y^2=-\frac{1}{K\tau_a^3}x^3$.
\subsection{I sistemi a fase minima}
Ci si accorge che per una significativa classe di sistemi, detti a fase minima, nella funzione di risposta armonica l'andamento del diagramma delle fasi è strettamente associato a quello delle ampiezze: se in una certa banda di frequenze l'ampiezza è costante, la fase tende ad essere nulla; una pendenza negativa del diagramma delle ampiezze è associata invece ad un ritardo di fase, una pendenza positiva ad un anticipo. 
Questa constatazione è teorizzata nella \textbf{formula di Bode}. Prima di enunciarla, però, definiamo i sistemi a fase minima come:
\begin{center}
    Consideriamo $\Sigma$ sistema lineare e stazionario con f.d.t. $G(s)$ e risposta armonica $G(j\omega)$. $\Sigma$ è detto a fase minima se il diagramma delle fasi $\beta=arg G(j\omega)$ è determinato univocamente, modulo $2\pi$, dal diagramma dei moduli $\alpha = ln|G(j\omega)|$ mediante la formula di Bode.
\end{center}
Se vale il contrario, il sistema è detto a \textbf{fase non minima}. Il progetto dei sistemi di controllo per questi ultimi è complesso. Un sistema con f.d.t. razionale è a fase minima s.s.e. non presenta poli o zeri a parte reale positiva.
\subsection{Formula di Bode}
Ricordiamo che
\begin{displaymath}
    \alpha := ln |G(j\omega)|, \beta := arg G(j\omega)
\end{displaymath}
Vogliamo trovare, una volta fissata una pulsazione $\omega_c$, il corrispondente argomento $\beta_c$. Introduciamo una variabile $u:=ln\frac{\omega}{\omega_c}=ln\omega-ln\omega_c$. Otteniamo infine 
\begin{displaymath}
    \beta_c = \frac{1}{\pi} \sum_{-\infty}^{+\infty}\frac{d\alpha}{du}ln cotgh|\frac{u}{2}|du \textrm{ se }lim_{\rightarrow0}s^h G(s)>0
\end{displaymath}
\begin{displaymath}
    \beta_c = \{\textrm{come sopra}\} - \pi \textrm{ se }lim_{\rightarrow0}s^h G(s)<0
\end{displaymath}
con $h$ tipo del sistema $\Sigma$, quindi $h=0$ se non vi sono poli né zeri nell'origine. $h>0$ se c'è un polo di molteplicità $h$ nell'origine, $h<0$ se c'è uno zero di molteplicità $|h|$ nell'origine.
Approfondiamo il discorso della funzione peso che compare. Notiamo che su una pendenza pari a 1, l'integrale vale $\frac{\pi}{2}$, da cui la regola pratica: se $\frac{d\alpha}{du}$ è costante per due decadi di pulsazione centrate su $\omega_c$, allora $\beta_c \approx \left(\frac{d\alpha}{du}\right)\cdot \frac{\pi}{2}$.
\subsection{Ritardi finiti}
Un ritardo finito è una funzione trascendente che nei sistemi di controllo assume particolare importanza: vogliamo ora approssimarli. Il fatto che sia una funzione trascendente crea qualche difficoltà: per questo l'approssimazione risulta utile. Introduciamo l'approssimante di Padè di $e^{-t_0s}$ di ordine q come 
\begin{displaymath}
    G_q(s;t_0) := \frac{\sum_{k=0}^q \frac{(sq-k)!q!}{(2q)!k!(q-k)!}(-1)^k t^k_0 s^k}{\sum_{k=0}^q \frac{(sq-k)!q!}{(2q)!k!(q-k)!} t^k_0 s^k}
\end{displaymath}
Notiamo una proprietà: lo sviluppo in serie di McLaurin coincide con l'analogo sviluppo di $e^{-t_0s}$. Questa coincidenza avviene fino alla potenza $(2q)$esima. In particolare, sviluppando $e^{-t_0s}$, all'aumentare di $q$ lo sviluppo è più preciso.
\begin{displaymath}
    e^{-t_0s} = 1- t_0s + \frac{t_0^2}{2!}s^2-\frac{t_0^3}{3!}s^3
\end{displaymath}
Calcolare l'approssimante del primo ordine è semplice: 
\begin{displaymath}
    G_1(s;t_0) = \frac{1-\frac{t_0}{2}s}{1+\frac{t_0}{2}s}
\end{displaymath}
Notiamo una simmetria tra zeri e poli e una stabilità asintotica.
L'approssimante di Padè del secondo ordine è invece 
\begin{displaymath}
    G_2(s;t_0) = \frac{1-\frac{t_0}{2}s + \frac{t_0^2}{12}s^2}{1+\frac{t_0}{2}s + \frac{t_0^2}{12}s^2}
\end{displaymath}
Interpretriamo il diagramma di Nyquist (polare) del ritardo finito: sarà evidentemente una circonferenza percorsa infinite volte: è chiaro che il ritardo aumenta linearmente all'aumentare $\omega$ e diverge all'infinito con $\omega\rightarrow\infty$. Analizziamo i diagrammi polari delle approssimanti: nel primo ordine abbiamo una semicirconferenza, nel secondo una circonferenza percorsa una sola volta, nel terzo una circonferenza percorsa una volta e mezzo.
\section{Sistemi retroazionati: proprietà ed analisi asintotica}
\subsection{Schemi a blocchi}
Gli \textbf{schemi a blocchi} vengono utilizzati per rappresentare sistemi complessi aventi un ingresso e un'uscita. Evidenziamo due variabili $u,y$, ingresso e uscita, e $k$, guadagno (numerico o funzione). I blocchi sono collegati tra di loro mediante i \textbf{punti di diramazione} e le \textbf{giunzioni sommanti}.
In generale è utile poter semplificare (ridurre) i blocchi tramite le cosiddette \textbf{regole di riduzione}. Ad esempio:
\begin{itemize}
    \item Riduzione di blocchi in cascata tramite eliminazione delle variabili di mezzo $z=K_1K_2x$
    \item Riduzione di blocchi in parallelo $k=k_1+k_2$
    \item Scambio di giunzioni sommanti (proprietà commutativa)
    \item Spostamento di prelievo di segnale a monte di un blocco
    \item Spostamento di prelievo di segnale a valle di un blocco 
    \item Spostamento di giunzione sommante a monte di un blocco 
    \item Spostamento di giunzione sommante a valle di un blocco 
    \item Eliminazione di un anello
\end{itemize}
\subsection{Proprietà generale dei sistemi in retroazione}
Esiste una regola rapida per il calcolo della f.d.t. dei sistemi retroazionati (singolo anello con il segnale retroazionato sottratto alla giunzione sommante):
\begin{displaymath}
    f.d.t. = \left\{\frac{\textrm{f.d.t. del percorso di segnale diretto}}{1+\textrm{guadagno di anello}}\right\}
\end{displaymath}
\subsubsection{Sensibilità a variazioni di parametri nei sistemi retroazionati}
Consideriamo un sistema definito da $T(s)=\frac{G(s)}{1+G(s)H(s)}$. Studiamo vari casi:
\begin{itemize}
    \item Variazione di un parametro nella catena diretta: $G(s)$ è in realtà $G(s;\alpha)$ con $\alpha=\alpha_0+\Delta\alpha$. Definiamo la sensibilità di T a variazioni di G come $\frac{\frac{\Delta T}{T(s;\alpha_0)}}{\frac{\Delta G}{G(s;\alpha_0)}}$. Otteniamo \begin{displaymath}
        S_G^T=\frac{1}{1+G(s;\alpha_0)H(s)}
    \end{displaymath} Quindi se il guadagno di anello è molto elevato, la var. relativa di T è molto più piccola della variazione relativa di G. Di conseguenza, un guadagno di anello elevato rende insensibile la f.d.t. del sistema retroazionato a variazioni della f.d.t. del sistema controllato. 
    \item Variazione di un parametro nella catena di retroazione: $H(s)$ è in realtà $H(s;\beta)$ con $\beta = \beta_0+\Delta\beta$. Otteniamo $S_H^T = \frac{dT}{dH}|_{\beta=\beta_0}=G\frac{-G}{(1+GH)^2}\cdot\frac{H}{\frac{G}{1+GH}}$ e infine $S_H^T = -\frac{G(s)H(s;\beta_0)}{1+G(s)H(s;\beta_0)}$. Quindi se il guadagno di anello è elevato la variazione relativa di T è circa uguale (in modulo) alla variazione relativa di H. Di conseguenza, variazioni della f.d.t. nella catena di retroazione si riverberano senza attenuazione in variazioni della f.d.t. del sistema retroazionato.
\end{itemize}
\subsection{Attenuazione dei disturbi}
Vediamo ora come può essere resa possibile un'attenuazione dei disturbi. Abbiamo per esempio un disturbo $D(s)$ su un sistema avente uscita normalmente uguale a $P(s)R(s)$. Vogliamo incrementare il rapporto segnale disturbo utlizzando un sistema retroazionato. A questo fine ipotizziamo che il disturbo sia indipendente da $R(s)$. Introduciamo un controllore $C(s)$. Per avere un confronto omogeneo si richiede $\frac{CP}{1+CPH} \approx P$, ossia che il sistema retroazionato non modifichi fortemente il comportamento. L'uscita determinata dal segnale utile è ora $P(s)R(s)$ mentre quella determinata dal disturbo è $\frac{P(s)}{1+C(s)P(s)H(s)}D(s)$, ottenendo un rapporto segnale disturbo pari a $\left(1+C(s)P(s)H(s)\right)\frac{R(s)}{D(s)}$. Quest'ultimo viene fortemente aumentato se nella banda di frequenze vale $|C(j\omega)P(j\omega)H(j\omega)|>>1$. In definitiva, se il guadagno di anello è elevato il rapporto segnale/disturbo si eleva all'incirca del medesimo fattore passando dallo schema in catena aperta a quello in catena chiusa. Quindi, a parità di segnale utile, il disturbo viene grandemente attenuato. 
\subsection{Allargamento della banda passante}
Ipotizziamo che $H(s) = h>0$. Significa quindi che la banda passante è infinita. Un guadagno di anello elevato implica un allargamento della banda passante. Sappiamo che \begin{displaymath}
    T(j\omega) = \frac{G(j\omega)}{1+hG(j\omega)}
\end{displaymath}
Quindi, se $h|G(j\omega) >> 1 \rightarrow T(j\omega) \approx 1/h$. 
Anche questo è un effetto benefico della retroazione. Possiamo esplicitare in termini quantitativi questo allargamento:
\begin{displaymath}
    G(j\omega)=\frac{1}{1+\tau j \omega} \rightarrow \omega_T = \frac{1+h}{\tau}
\end{displaymath}
\subsection{Analisi a regime dei sistemi in retroazione}
Vogliamo ora studiare l'errore di regolazione a regime in risposta a segnali tipici. Ipotizziamo un sistema asintoticamente stabile, e a retroazione unitaria (nessun blocco $H(s)$). I segnali tipici che consideriamo sono $r(t) \in \left\{r_0 1(t), r_0t1(t), r_0\frac{t^2}{2}1(t)\right\}$, quindi il gradino unitario, una rampa, una parabola (tutti caratterizzati da $r_0$). Sappiamo che $e(t) := r(t)-y(t)$ (errore a regime), ne calcoliamo la trasformata $E(s)=\frac{1}{1+G(s)}R(s)$ (catena diretta fratto guadagno di anello moltiplicato per la trasformata del segnale di ingresso). L'errore a regime è quindi $e_r := lim_{t\rightarrow\infty} e(t)$. Ricordiamo anche che $h$ è il tipo del sistema. 
\subsubsection{Gradino}
Dopo un transitorio, l'uscita si stabilizza su un valore costante. Calcoliamo l'errore:
\begin{displaymath}
    e_r = lim_{s\rightarrow0} sE(s) = \frac{r_0}{1+K_p}
\end{displaymath}
con $K_p := ilm_{s\rightarrow0}G(s)$ costante di posizione.
\subsubsection{Rampa}
Ora, abbiamo 
\begin{displaymath}
    r(t) = r_0 t1(t) \rightarrow R(s) = \frac{r_0}{s^2}
\end{displaymath}
\begin{displaymath}
    e_r = \frac{r_0}{K_v}
\end{displaymath}
con $K_v := lim_{s\rightarrow0}sG(s)$ costante di velocità.
\subsubsection{Parabola}
Abbiamo infine 
\begin{displaymath}
    r(t) = r_0 \frac{t^2}{2}1(t) \rightarrow R(s)=\frac{r_0}{s^3}
\end{displaymath}
\begin{displaymath}
    e_r = \frac{r_0}{K_a}
\end{displaymath}
con $K_a := lim_{s\rightarrow0} s^2G(s)$ costante di accelerazione. 
\subsection{Errore a regime con retroazione non unitaria}
Ipotizziamo ora che la retroazione non sia unitaria: la variabile controllata $y$ è in generale dimensionalmente diversa dal segnale di set-point $r$ e quindi occorre definire la condizione ideale di controllo:
\begin{displaymath}
    y(t) \equiv K_c r(t)
\end{displaymath}
dove $K_c$ è detta costante di controllo o regolazione. Abbiamo quindi una variabile errore definita, ad esempio, come $e(t):=r(t) - \gamma y(t), \gamma=1/K_c$, e quindi $e(t) \equiv 0 \leftrightarrow y(t) \equiv K_cr(t)$. 
Potremmo applicare il teorema del valore finale, ma ci conviene utilizzare i risultati ottenuti precedentemente trasformando il sistema in uno con retroazione unitaria, con guadagno dato da 
\begin{displaymath}
    G_E(s) = \frac{G(s)\gamma}{1+G(s)(H(s)-\gamma)}
\end{displaymath}
Se avessimo $H(s) = h$ e $K_c = 1/h \rightarrow G_E(s) = G(s)h$.
\end{document}


